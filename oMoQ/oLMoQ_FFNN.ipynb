{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 494
    },
    "id": "g1kdAn67Ase-",
    "outputId": "bf6c176e-d6ab-41ce-944b-780e34978097"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting git+https://github.com/indra-ipd/scipy.git\n",
      "  Cloning https://github.com/indra-ipd/scipy.git to /tmp/pip-req-build-vqp77x2r\n",
      "  Running command git clone -q https://github.com/indra-ipd/scipy.git /tmp/pip-req-build-vqp77x2r\n",
      "  Running command git submodule update --init --recursive -q\n",
      "  From https://github.com/scipy/boost-headers-only\n",
      "   * branch            2110ce20e59917b85b12059b3ddd8b133549f662 -> FETCH_HEAD\n",
      "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
      "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
      "    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n",
      "Requirement already satisfied: numpy>=1.16.5 in /usr/local/lib/python3.7/dist-packages (from scipy==1.7.0.dev0+1032.253cdda) (1.19.5)\n",
      "Building wheels for collected packages: scipy\n",
      "  Building wheel for scipy (PEP 517) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for scipy: filename=scipy-1.7.0.dev0+1032.253cdda-cp37-cp37m-linux_x86_64.whl size=56685333 sha256=49da1b308ace7e7e9803a43d49ec0b642048bf12097418be52b4542f1f09b7be\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-hpoegiih/wheels/3d/e4/26/f8c192c4555c2f4643b23b020176fb3638f7fd22c1069269d6\n",
      "Successfully built scipy\n",
      "Installing collected packages: scipy\n",
      "  Attempting uninstall: scipy\n",
      "    Found existing installation: scipy 1.4.1\n",
      "    Uninstalling scipy-1.4.1:\n",
      "      Successfully uninstalled scipy-1.4.1\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "albumentations 0.1.12 requires imgaug<0.2.7,>=0.2.5, but you have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
      "Successfully installed scipy-1.7.0.dev0+1032.253cdda\n"
     ]
    },
    {
     "data": {
      "application/vnd.colab-display-data+json": {
       "pip_warning": {
        "packages": [
         "scipy"
        ]
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "import tensorflow as tf\n",
    "!pip install git+https://github.com/indra-ipd/scipy.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "1teynEIeA0Ss"
   },
   "outputs": [],
   "source": [
    "import logging\n",
    "logger = logging.getLogger()\n",
    "logger.setLevel(logging.CRITICAL)\n",
    "import logging, sys\n",
    "logging.disable(sys.maxsize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AV6JYOLYA_eD",
    "outputId": "607c6c11-8d77-4b71-c996-2e3db192e218"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow 1.x selected.\n"
     ]
    }
   ],
   "source": [
    "%tensorflow_version 1.x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "i6L0DlXLBARR"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import collections\n",
    "import time\n",
    "from sklearn import datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3qyE5R7ABVuk",
    "outputId": "b7fdaf5a-8097-4a11-bd8c-25796e2ac940"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting /tmp/data/train-images-idx3-ubyte.gz\n",
      "Extracting /tmp/data/train-labels-idx1-ubyte.gz\n",
      "Extracting /tmp/data/t10k-images-idx3-ubyte.gz\n",
      "Extracting /tmp/data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "# Import MNIST data (http://yann.lecun.com/exdb/mnist/)\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\"/tmp/data/\", one_hot=True)\n",
    "Xtrain, Ytrain, Xtest, Ytest = mnist.train.images, mnist.train.labels, mnist.test.images, mnist.test.labels\n",
    "\n",
    "seed = np.random.randint(100)\n",
    "tf.set_random_seed(seed)\n",
    "image_size = 28\n",
    "chan_num = 1\n",
    "labels_size = 10\n",
    "learning_rate = 0.001\n",
    "batch_size = 128\n",
    "batches = int(len(Ytrain) / batch_size)\n",
    "iterations = batches\n",
    "\n",
    "epoch = 10\n",
    "\n",
    "algo = ['oLMoQ','oLNAQ','oLBFGS','Adam']\n",
    "col = {'oNAQ': 'b', 'oMoQ': 'm', 'oBFGS': 'g', 'oLNAQ': 'b', 'oLMoQ': 'm', 'oLBFGS': 'g','Adam': 'r'}\n",
    "#col = {'oNAQ': 'b', 'oMoQ': 'm', 'oBFGS': 'g', 'oLNAQ': '#00CED1', 'oLMoQ': '#DAA520', 'oLBFGS': '#90EE90','Adam': 'r'}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "lQKeNB7LBces"
   },
   "outputs": [],
   "source": [
    "training_data = tf.placeholder(tf.float32, [None, image_size*image_size*chan_num])\n",
    "labels = tf.placeholder(tf.float32, [None, labels_size])\n",
    "\n",
    "L1 = tf.contrib.layers.fully_connected(inputs=training_data, num_outputs=100, activation_fn=tf.nn.relu,normalizer_fn=tf.contrib.layers.batch_norm)\n",
    "L2 = tf.contrib.layers.fully_connected(inputs=L1, num_outputs=50, activation_fn=tf.nn.relu,normalizer_fn=tf.contrib.layers.batch_norm)\n",
    "#L3 = tf.contrib.layers.fully_connected(inputs=L2, num_outputs=16, activation_fn=tf.nn.sigmoid)\n",
    "output = tf.contrib.layers.fully_connected(inputs=L2, num_outputs=10, activation_fn=tf.nn.softmax)\n",
    "\n",
    "#loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=labels, logits=output))\n",
    "loss = tf.reduce_mean(-tf.reduce_sum(labels*tf.log(output), reduction_indices=1))\n",
    "\n",
    "correct_prediction = tf.equal(tf.argmax(output, 1), tf.argmax(labels, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "vWE26m94BgCd"
   },
   "outputs": [],
   "source": [
    "perm_idx = []\n",
    "for num in range(500):\n",
    "    perm_idx.append(np.random.permutation(len(Ytrain)))\n",
    "\n",
    "\n",
    "\n",
    "def get_batches(x_tr,y_tr, size,ep_num):\n",
    "\n",
    "    #shuffle data\n",
    "    #idx = np.random.permutation(len(y_tr))\n",
    "    idx = perm_idx[ep_num-1]\n",
    "    x_tr, y_tr = x_tr[idx], y_tr[idx]\n",
    "\n",
    "    num_batch = int(len(y_tr)/size)\n",
    "    data = []\n",
    "    lab = []\n",
    "    for i in range(num_batch):\n",
    "        data.append(x_tr[i*size:i*size+size])\n",
    "        lab.append(y_tr[i * size:i * size + size])\n",
    "    return data,lab\n",
    "\n",
    "def update(l, a):\n",
    "    global train_loss, train_acc\n",
    "    train_loss = l\n",
    "    train_acc = a\n",
    "\n",
    "count = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nfpmKHUFBk8d",
    "outputId": "f7499fec-6547-4f7c-8c15-5484b60929f0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial Error of  oLMoQ  :  2.6321366\n",
      "EPOCH  1  : ##########\n",
      "Parameters:  84060\n",
      "Step 0; train loss 1.2892625331878662; train accuracy 68.75; test loss 1.664481282234192; test accuracy 44.94999945163727; alpha 0.9; mu 0.8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tensorflow-1.15.2/python3.7/tensorflow_core/contrib/opt/python/training/external_optimizer.py:402: OptimizeWarning: Unknown solver options: Hk_mat\n",
      "  result = scipy.optimize.minimize(*minimize_args, **minimize_kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 50; train loss 0.24076008796691895; train accuracy 90.625; test loss 0.23984628915786743; test accuracy 93.11000108718872; alpha 0.14002800840280097; mu 0.8\n",
      "Step 100; train loss 0.28250157833099365; train accuracy 91.40625; test loss 0.19142597913742065; test accuracy 94.38999891281128; alpha 0.09950371902099892; mu 0.8\n",
      "Step 150; train loss 0.21201840043067932; train accuracy 93.75; test loss 0.16929002106189728; test accuracy 95.02999782562256; alpha 0.08137884587711594; mu 0.8\n",
      "Step 200; train loss 0.30750513076782227; train accuracy 89.0625; test loss 0.15589341521263123; test accuracy 95.35999894142151; alpha 0.07053456158585983; mu 0.8\n",
      "Step 250; train loss 0.19027021527290344; train accuracy 94.53125; test loss 0.1459905505180359; test accuracy 95.7099974155426; alpha 0.06311944030978031; mu 0.8\n",
      "Step 300; train loss 0.1181061789393425; train accuracy 98.4375; test loss 0.13894134759902954; test accuracy 95.81999778747559; alpha 0.0576390417704235; mu 0.8\n",
      "Step 350; train loss 0.24100032448768616; train accuracy 93.75; test loss 0.1318623423576355; test accuracy 96.06000185012817; alpha 0.05337605126836238; mu 0.8\n",
      "Step 400; train loss 0.13715097308158875; train accuracy 96.875; test loss 0.1264447122812271; test accuracy 96.23000025749207; alpha 0.04993761694389223; mu 0.8\n",
      "EPOCH  2  : ##########\n",
      "Step 0; train loss 0.15500092506408691; train accuracy 95.3125; test loss 0.12390363961458206; test accuracy 96.29999995231628; alpha 0.04822428221704121; mu 0.8\n",
      "Step 50; train loss 0.10043160617351532; train accuracy 96.09375; test loss 0.11880018562078476; test accuracy 96.42999768257141; alpha 0.04564354645876384; mu 0.8\n",
      "Step 100; train loss 0.07291637361049652; train accuracy 98.4375; test loss 0.11938604712486267; test accuracy 96.35999798774719; alpha 0.04343722427630694; mu 0.8\n",
      "Step 150; train loss 0.08550076931715012; train accuracy 96.875; test loss 0.11489508301019669; test accuracy 96.41000032424927; alpha 0.041522739926869986; mu 0.8\n",
      "Step 200; train loss 0.024790629744529724; train accuracy 100.0; test loss 0.11090674996376038; test accuracy 96.670001745224; alpha 0.03984095364447979; mu 0.8\n",
      "Step 250; train loss 0.06829726696014404; train accuracy 99.21875; test loss 0.10902639478445053; test accuracy 96.7199981212616; alpha 0.03834824944236852; mu 0.8\n",
      "Step 300; train loss 0.07873301953077316; train accuracy 97.65625; test loss 0.10685107111930847; test accuracy 96.81000113487244; alpha 0.037011660509880265; mu 0.8\n",
      "Step 350; train loss 0.12753862142562866; train accuracy 96.09375; test loss 0.10360624641180038; test accuracy 96.79999947547913; alpha 0.03580574370197165; mu 0.8\n",
      "Step 400; train loss 0.12272608280181885; train accuracy 96.09375; test loss 0.1023823544383049; test accuracy 97.04999923706055; alpha 0.03471050672503116; mu 0.8\n",
      "EPOCH  3  : ##########\n",
      "Step 0; train loss 0.08124695718288422; train accuracy 96.875; test loss 0.10037563741207123; test accuracy 96.99000120162964; alpha 0.03411955969674702; mu 0.8\n",
      "Step 50; train loss 0.062265437096357346; train accuracy 99.21875; test loss 0.0982680395245552; test accuracy 97.04999923706055; alpha 0.033167906340332974; mu 0.8\n",
      "Step 100; train loss 0.13837368786334991; train accuracy 96.09375; test loss 0.09553229808807373; test accuracy 97.10000157356262; alpha 0.03229168418603133; mu 0.8\n",
      "Step 150; train loss 0.05723876133561134; train accuracy 98.4375; test loss 0.09421326220035553; test accuracy 97.10999727249146; alpha 0.031481427501027934; mu 0.8\n",
      "Step 200; train loss 0.04499031975865364; train accuracy 99.21875; test loss 0.09549026191234589; test accuracy 97.14999794960022; alpha 0.030729254193150105; mu 0.8\n",
      "Step 250; train loss 0.05802468582987785; train accuracy 98.4375; test loss 0.09461107105016708; test accuracy 97.14999794960022; alpha 0.03002854067691021; mu 0.8\n",
      "Step 300; train loss 0.06160612031817436; train accuracy 98.4375; test loss 0.09362880140542984; test accuracy 97.06000089645386; alpha 0.029373674772302332; mu 0.8\n",
      "Step 350; train loss 0.0429687425494194; train accuracy 99.21875; test loss 0.0927124172449112; test accuracy 97.15999960899353; alpha 0.028759865427152538; mu 0.8\n",
      "Step 400; train loss 0.09990890324115753; train accuracy 98.4375; test loss 0.0932052955031395; test accuracy 97.14000225067139; alpha 0.028182994438777077; mu 0.8\n",
      "EPOCH  4  : ##########\n",
      "Step 0; train loss 0.08141756057739258; train accuracy 97.65625; test loss 0.09243684262037277; test accuracy 97.17000126838684; alpha 0.02786391062876764; mu 0.8\n",
      "Step 50; train loss 0.06862381845712662; train accuracy 99.21875; test loss 0.09340173006057739; test accuracy 97.02000021934509; alpha 0.027338327590690405; mu 0.8\n",
      "Step 100; train loss 0.034980058670043945; train accuracy 99.21875; test loss 0.09048594534397125; test accuracy 97.21999764442444; alpha 0.02684140635475095; mu 0.8\n",
      "Step 150; train loss 0.09748759865760803; train accuracy 97.65625; test loss 0.09294707328081131; test accuracy 97.2000002861023; alpha 0.026370633137494492; mu 0.8\n",
      "Step 200; train loss 0.06809933483600616; train accuracy 98.4375; test loss 0.08886974304914474; test accuracy 97.32999801635742; alpha 0.02592379236826063; mu 0.8\n",
      "Step 250; train loss 0.06065883859992027; train accuracy 97.65625; test loss 0.08658687770366669; test accuracy 97.4399983882904; alpha 0.02549892269327383; mu 0.8\n",
      "Step 300; train loss 0.026728294789791107; train accuracy 99.21875; test loss 0.08638960868120193; test accuracy 97.42000102996826; alpha 0.02509428066142478; mu 0.8\n",
      "Step 350; train loss 0.049936167895793915; train accuracy 97.65625; test loss 0.08617382496595383; test accuracy 97.46999740600586; alpha 0.024708310555370042; mu 0.8\n",
      "Step 400; train loss 0.056337594985961914; train accuracy 98.4375; test loss 0.08580438047647476; test accuracy 97.49000072479248; alpha 0.024339619175561773; mu 0.8\n",
      "EPOCH  5  : ##########\n",
      "Step 0; train loss 0.024316325783729553; train accuracy 100.0; test loss 0.08558712154626846; test accuracy 97.49000072479248; alpha 0.02413319668619763; mu 0.8\n",
      "Step 50; train loss 0.08720128983259201; train accuracy 97.65625; test loss 0.0838547945022583; test accuracy 97.35000133514404; alpha 0.023789303403490326; mu 0.8\n",
      "Step 100; train loss 0.045727647840976715; train accuracy 100.0; test loss 0.08421797305345535; test accuracy 97.43000268936157; alpha 0.023459704442429407; mu 0.8\n",
      "Step 150; train loss 0.041851408779621124; train accuracy 99.21875; test loss 0.08232550323009491; test accuracy 97.42000102996826; alpha 0.023143436208321693; mu 0.8\n",
      "Step 200; train loss 0.024224739521741867; train accuracy 100.0; test loss 0.08402391523122787; test accuracy 97.50000238418579; alpha 0.022839623660917723; mu 0.8\n",
      "Step 250; train loss 0.0465269610285759; train accuracy 98.4375; test loss 0.08355922996997833; test accuracy 97.53000140190125; alpha 0.0225474701184918; mu 0.8\n",
      "Step 300; train loss 0.048260219395160675; train accuracy 99.21875; test loss 0.08284250646829605; test accuracy 97.46999740600586; alpha 0.0222662484609674; mu 0.8\n",
      "Step 350; train loss 0.08642621338367462; train accuracy 96.09375; test loss 0.08309192955493927; test accuracy 97.54999876022339; alpha 0.021995293510729184; mu 0.8\n",
      "Step 400; train loss 0.08580544590950012; train accuracy 97.65625; test loss 0.08160565048456192; test accuracy 97.61000275611877; alpha 0.02173399540921557; mu 0.8\n",
      "EPOCH  6  : ##########\n",
      "Step 0; train loss 0.057888180017471313; train accuracy 98.4375; test loss 0.08089357614517212; test accuracy 97.64000177383423; alpha 0.021586644588817278; mu 0.8\n",
      "Step 50; train loss 0.04403292387723923; train accuracy 98.4375; test loss 0.08212225139141083; test accuracy 97.51999974250793; alpha 0.021339479988815996; mu 0.8\n",
      "Step 100; train loss 0.049356866627931595; train accuracy 97.65625; test loss 0.08114110678434372; test accuracy 97.61999845504761; alpha 0.021100615513931942; mu 0.8\n",
      "Step 150; train loss 0.023947982117533684; train accuracy 100.0; test loss 0.08288363367319107; test accuracy 97.50000238418579; alpha 0.020869596778242055; mu 0.8\n",
      "Step 200; train loss 0.11874394118785858; train accuracy 96.09375; test loss 0.08117379248142242; test accuracy 97.57999777793884; alpha 0.02064600347538335; mu 0.8\n",
      "Step 250; train loss 0.08016222715377808; train accuracy 97.65625; test loss 0.08284193277359009; test accuracy 97.50999808311462; alpha 0.020429446161135924; mu 0.8\n",
      "Step 300; train loss 0.027021022513508797; train accuracy 100.0; test loss 0.07929142564535141; test accuracy 97.54999876022339; alpha 0.020219563399637347; mu 0.8\n",
      "Step 350; train loss 0.052081283181905746; train accuracy 99.21875; test loss 0.08013442158699036; test accuracy 97.50999808311462; alpha 0.02001601922563589; mu 0.8\n",
      "Step 400; train loss 0.09657509624958038; train accuracy 95.3125; test loss 0.08046478778123856; test accuracy 97.61999845504761; alpha 0.01981850088223545; mu 0.8\n",
      "EPOCH  7  : ##########\n",
      "Step 0; train loss 0.08278942108154297; train accuracy 97.65625; test loss 0.07972307503223419; test accuracy 97.58999943733215; alpha 0.019706585563285865; mu 0.8\n",
      "Step 50; train loss 0.010842246934771538; train accuracy 100.0; test loss 0.07903124392032623; test accuracy 97.61000275611877; alpha 0.019518001458970664; mu 0.8\n",
      "Step 100; train loss 0.05064301937818527; train accuracy 98.4375; test loss 0.07957064360380173; test accuracy 97.61999845504761; alpha 0.019334729780913273; mu 0.8\n",
      "Step 150; train loss 0.07259157299995422; train accuracy 97.65625; test loss 0.0790359377861023; test accuracy 97.5600004196167; alpha 0.019156525704423027; mu 0.8\n",
      "Step 200; train loss 0.08643977344036102; train accuracy 96.09375; test loss 0.08039967715740204; test accuracy 97.50999808311462; alpha 0.01898315991504998; mu 0.8\n",
      "Step 250; train loss 0.03755856305360794; train accuracy 99.21875; test loss 0.07954874634742737; test accuracy 97.51999974250793; alpha 0.018814417367671945; mu 0.8\n",
      "Step 300; train loss 0.041122086346149445; train accuracy 99.21875; test loss 0.07772396504878998; test accuracy 97.61999845504761; alpha 0.018650096164806278; mu 0.8\n",
      "Step 350; train loss 0.05957457423210144; train accuracy 98.4375; test loss 0.07701151072978973; test accuracy 97.72999882698059; alpha 0.018490006540840973; mu 0.8\n",
      "Step 400; train loss 0.017231307923793793; train accuracy 100.0; test loss 0.07855220884084702; test accuracy 97.53000140190125; alpha 0.018333969940564226; mu 0.8\n",
      "EPOCH  8  : ##########\n",
      "Step 0; train loss 0.020476900041103363; train accuracy 99.21875; test loss 0.07773834466934204; test accuracy 97.57000207901001; alpha 0.01824525912922067; mu 0.8\n",
      "Step 50; train loss 0.08443401753902435; train accuracy 97.65625; test loss 0.07688132673501968; test accuracy 97.5600004196167; alpha 0.018095287334182187; mu 0.8\n",
      "Step 100; train loss 0.03932613134384155; train accuracy 97.65625; test loss 0.07655319571495056; test accuracy 97.63000011444092; alpha 0.017948953965443454; mu 0.8\n",
      "Step 150; train loss 0.051917195320129395; train accuracy 97.65625; test loss 0.07753022760152817; test accuracy 97.57999777793884; alpha 0.017806114244894065; mu 0.8\n",
      "Step 200; train loss 0.05389776825904846; train accuracy 98.4375; test loss 0.07938282191753387; test accuracy 97.50999808311462; alpha 0.017666631333439334; mu 0.8\n",
      "Step 250; train loss 0.068956658244133; train accuracy 99.21875; test loss 0.07897572219371796; test accuracy 97.61000275611877; alpha 0.0175303757799037; mu 0.8\n",
      "Step 300; train loss 0.026312895119190216; train accuracy 100.0; test loss 0.07880114018917084; test accuracy 97.57000207901001; alpha 0.017397225015980525; mu 0.8\n",
      "Step 350; train loss 0.044339556246995926; train accuracy 98.4375; test loss 0.07663434743881226; test accuracy 97.64999747276306; alpha 0.017267062892749267; mu 0.8\n",
      "Step 400; train loss 0.029245946556329727; train accuracy 99.21875; test loss 0.07824404537677765; test accuracy 97.5600004196167; alpha 0.017139779254776524; mu 0.8\n",
      "EPOCH  9  : ##########\n",
      "Step 0; train loss 0.04503469169139862; train accuracy 98.4375; test loss 0.07814863324165344; test accuracy 97.64000177383423; alpha 0.0170672322461873; mu 0.8\n",
      "Step 50; train loss 0.055512502789497375; train accuracy 99.21875; test loss 0.07764140516519547; test accuracy 97.67000079154968; alpha 0.01694428559251163; mu 0.8\n",
      "Step 100; train loss 0.03917466476559639; train accuracy 99.21875; test loss 0.07701759040355682; test accuracy 97.60000109672546; alpha 0.016823958224413904; mu 0.8\n",
      "Step 150; train loss 0.043245021253824234; train accuracy 99.21875; test loss 0.07977329939603806; test accuracy 97.5600004196167; alpha 0.01670615844038759; mu 0.8\n",
      "Step 200; train loss 0.02600128948688507; train accuracy 99.21875; test loss 0.07766745239496231; test accuracy 97.58999943733215; alpha 0.016590798971560294; mu 0.8\n",
      "Step 250; train loss 0.024861235171556473; train accuracy 100.0; test loss 0.07542146742343903; test accuracy 97.69999980926514; alpha 0.016477796709963355; mu 0.8\n",
      "Step 300; train loss 0.060594767332077026; train accuracy 99.21875; test loss 0.0762181356549263; test accuracy 97.64000177383423; alpha 0.016367072456887358; mu 0.8\n",
      "Step 350; train loss 0.05520930886268616; train accuracy 99.21875; test loss 0.07772599160671234; test accuracy 97.61000275611877; alpha 0.016258550689592154; mu 0.8\n",
      "Step 400; train loss 0.07346893101930618; train accuracy 97.65625; test loss 0.07690364122390747; test accuracy 97.61999845504761; alpha 0.01615215934480992; mu 0.8\n",
      "EPOCH  10  : ##########\n",
      "Step 0; train loss 0.03053322806954384; train accuracy 99.21875; test loss 0.07651318609714508; test accuracy 97.71999716758728; alpha 0.01609140128253687; mu 0.8\n",
      "Step 50; train loss 0.0310116745531559; train accuracy 98.4375; test loss 0.0759957805275917; test accuracy 97.61000275611877; alpha 0.015988236984776985; mu 0.8\n",
      "Step 100; train loss 0.0355205237865448; train accuracy 99.21875; test loss 0.07454395294189453; test accuracy 97.64000177383423; alpha 0.01588703178380234; mu 0.8\n",
      "Step 150; train loss 0.01890448108315468; train accuracy 100.0; test loss 0.07565528154373169; test accuracy 97.71000146865845; alpha 0.015787724448766815; mu 0.8\n",
      "Step 200; train loss 0.0633791834115982; train accuracy 99.21875; test loss 0.07543850690126419; test accuracy 97.67000079154968; alpha 0.015690256395005604; mu 0.8\n",
      "Step 250; train loss 0.04231235757470131; train accuracy 98.4375; test loss 0.0756470188498497; test accuracy 97.61999845504761; alpha 0.015594571538795133; mu 0.8\n",
      "Step 300; train loss 0.038317445665597916; train accuracy 98.4375; test loss 0.0751788467168808; test accuracy 97.64000177383423; alpha 0.015500616161738888; mu 0.8\n",
      "Step 350; train loss 0.037314191460609436; train accuracy 100.0; test loss 0.07423701882362366; test accuracy 97.69999980926514; alpha 0.015408338784034142; mu 0.8\n",
      "Step 400; train loss 0.04903174191713333; train accuracy 98.4375; test loss 0.07531609386205673; test accuracy 97.67000079154968; alpha 0.015317690045940371; mu 0.8\n",
      "Initial Error of  oLNAQ  :  2.6321366\n",
      "EPOCH  1  : ##########\n",
      "Parameters:  84060\n",
      "Step 0; train loss 1.2892625331878662; train accuracy 68.75; test loss 1.664481282234192; test accuracy 44.94999945163727; alpha 0.9; mu 0.8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tensorflow-1.15.2/python3.7/tensorflow_core/contrib/opt/python/training/external_optimizer.py:402: OptimizeWarning: Unknown solver options: Hk_mat\n",
      "  result = scipy.optimize.minimize(*minimize_args, **minimize_kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 50; train loss 0.17399108409881592; train accuracy 95.3125; test loss 0.20855717360973358; test accuracy 93.80000233650208; alpha 0.14002800840280097; mu 0.8\n",
      "Step 100; train loss 0.18654906749725342; train accuracy 92.96875; test loss 0.1707148253917694; test accuracy 94.66999769210815; alpha 0.09950371902099892; mu 0.8\n",
      "Step 150; train loss 0.1538209170103073; train accuracy 95.3125; test loss 0.14442192018032074; test accuracy 95.74999809265137; alpha 0.08137884587711594; mu 0.8\n",
      "Step 200; train loss 0.2395225465297699; train accuracy 91.40625; test loss 0.1320999264717102; test accuracy 95.99000215530396; alpha 0.07053456158585983; mu 0.8\n",
      "Step 250; train loss 0.18236678838729858; train accuracy 94.53125; test loss 0.12463902682065964; test accuracy 96.17999792098999; alpha 0.06311944030978031; mu 0.8\n",
      "Step 300; train loss 0.06560562551021576; train accuracy 99.21875; test loss 0.11419551819562912; test accuracy 96.52000069618225; alpha 0.0576390417704235; mu 0.8\n",
      "Step 350; train loss 0.17134852707386017; train accuracy 93.75; test loss 0.10771983861923218; test accuracy 96.52000069618225; alpha 0.05337605126836238; mu 0.8\n",
      "Step 400; train loss 0.1001514419913292; train accuracy 96.09375; test loss 0.10628119111061096; test accuracy 96.74000144004822; alpha 0.04993761694389223; mu 0.8\n",
      "EPOCH  2  : ##########\n",
      "Step 0; train loss 0.08221960067749023; train accuracy 96.875; test loss 0.10537087172269821; test accuracy 96.71000242233276; alpha 0.04822428221704121; mu 0.8\n",
      "Step 50; train loss 0.02654903009533882; train accuracy 100.0; test loss 0.0969335213303566; test accuracy 97.03999757766724; alpha 0.04564354645876384; mu 0.8\n",
      "Step 100; train loss 0.05813636630773544; train accuracy 99.21875; test loss 0.09657704830169678; test accuracy 97.10999727249146; alpha 0.04343722427630694; mu 0.8\n",
      "Step 150; train loss 0.08449211716651917; train accuracy 96.875; test loss 0.0930081158876419; test accuracy 97.04999923706055; alpha 0.041522739926869986; mu 0.8\n",
      "Step 200; train loss 0.01301940344274044; train accuracy 100.0; test loss 0.09072654694318771; test accuracy 97.22999930381775; alpha 0.03984095364447979; mu 0.8\n",
      "Step 250; train loss 0.04894140362739563; train accuracy 98.4375; test loss 0.08892567455768585; test accuracy 97.18000292778015; alpha 0.03834824944236852; mu 0.8\n",
      "Step 300; train loss 0.052005209028720856; train accuracy 98.4375; test loss 0.08381374180316925; test accuracy 97.3800003528595; alpha 0.037011660509880265; mu 0.8\n",
      "Step 350; train loss 0.08652189373970032; train accuracy 96.875; test loss 0.08377242088317871; test accuracy 97.47999906539917; alpha 0.03580574370197165; mu 0.8\n",
      "Step 400; train loss 0.08680535852909088; train accuracy 96.09375; test loss 0.07862832397222519; test accuracy 97.53999710083008; alpha 0.03471050672503116; mu 0.8\n",
      "EPOCH  3  : ##########\n",
      "Step 0; train loss 0.0729074776172638; train accuracy 97.65625; test loss 0.08059704303741455; test accuracy 97.50999808311462; alpha 0.03411955969674702; mu 0.8\n",
      "Step 50; train loss 0.048655446618795395; train accuracy 98.4375; test loss 0.07755514234304428; test accuracy 97.5600004196167; alpha 0.033167906340332974; mu 0.8\n",
      "Step 100; train loss 0.06508255749940872; train accuracy 98.4375; test loss 0.07663346827030182; test accuracy 97.64999747276306; alpha 0.03229168418603133; mu 0.8\n",
      "Step 150; train loss 0.031209349632263184; train accuracy 98.4375; test loss 0.07519648224115372; test accuracy 97.64999747276306; alpha 0.031481427501027934; mu 0.8\n",
      "Step 200; train loss 0.018860844895243645; train accuracy 100.0; test loss 0.07743332535028458; test accuracy 97.57000207901001; alpha 0.030729254193150105; mu 0.8\n",
      "Step 250; train loss 0.04049808159470558; train accuracy 98.4375; test loss 0.07493006438016891; test accuracy 97.64999747276306; alpha 0.03002854067691021; mu 0.8\n",
      "Step 300; train loss 0.04463876411318779; train accuracy 97.65625; test loss 0.07526963949203491; test accuracy 97.67000079154968; alpha 0.029373674772302332; mu 0.8\n",
      "Step 350; train loss 0.028251809999346733; train accuracy 98.4375; test loss 0.07690073549747467; test accuracy 97.46999740600586; alpha 0.028759865427152538; mu 0.8\n",
      "Step 400; train loss 0.10673923045396805; train accuracy 97.65625; test loss 0.07840408384799957; test accuracy 97.50000238418579; alpha 0.028182994438777077; mu 0.8\n",
      "EPOCH  4  : ##########\n",
      "Step 0; train loss 0.025707630440592766; train accuracy 100.0; test loss 0.07309571653604507; test accuracy 97.75999784469604; alpha 0.02786391062876764; mu 0.8\n",
      "Step 50; train loss 0.03888363391160965; train accuracy 99.21875; test loss 0.07524276524782181; test accuracy 97.60000109672546; alpha 0.027338327590690405; mu 0.8\n",
      "Step 100; train loss 0.029480300843715668; train accuracy 99.21875; test loss 0.07617440819740295; test accuracy 97.58999943733215; alpha 0.02684140635475095; mu 0.8\n",
      "Step 150; train loss 0.06156981736421585; train accuracy 96.875; test loss 0.07499098032712936; test accuracy 97.67000079154968; alpha 0.026370633137494492; mu 0.8\n",
      "Step 200; train loss 0.05245409905910492; train accuracy 98.4375; test loss 0.07146807760000229; test accuracy 97.79000282287598; alpha 0.02592379236826063; mu 0.8\n",
      "Step 250; train loss 0.04433828964829445; train accuracy 99.21875; test loss 0.0732005164027214; test accuracy 97.69999980926514; alpha 0.02549892269327383; mu 0.8\n",
      "Step 300; train loss 0.018883783370256424; train accuracy 99.21875; test loss 0.07348226010799408; test accuracy 97.75999784469604; alpha 0.02509428066142478; mu 0.8\n",
      "Step 350; train loss 0.02977283112704754; train accuracy 98.4375; test loss 0.07350029051303864; test accuracy 97.72999882698059; alpha 0.024708310555370042; mu 0.8\n",
      "Step 400; train loss 0.0248638354241848; train accuracy 100.0; test loss 0.07332094013690948; test accuracy 97.7400004863739; alpha 0.024339619175561773; mu 0.8\n",
      "EPOCH  5  : ##########\n",
      "Step 0; train loss 0.007105914875864983; train accuracy 100.0; test loss 0.07284374535083771; test accuracy 97.57000207901001; alpha 0.02413319668619763; mu 0.8\n",
      "Step 50; train loss 0.04610460624098778; train accuracy 99.21875; test loss 0.07033087313175201; test accuracy 97.86999821662903; alpha 0.023789303403490326; mu 0.8\n",
      "Step 100; train loss 0.021475451067090034; train accuracy 100.0; test loss 0.07268624007701874; test accuracy 97.81000018119812; alpha 0.023459704442429407; mu 0.8\n",
      "Step 150; train loss 0.007398515939712524; train accuracy 100.0; test loss 0.07035353034734726; test accuracy 97.79000282287598; alpha 0.023143436208321693; mu 0.8\n",
      "Step 200; train loss 0.009265273809432983; train accuracy 100.0; test loss 0.07242509722709656; test accuracy 97.72999882698059; alpha 0.022839623660917723; mu 0.8\n",
      "Step 250; train loss 0.012045291252434254; train accuracy 100.0; test loss 0.06978625804185867; test accuracy 97.83999919891357; alpha 0.0225474701184918; mu 0.8\n",
      "Step 300; train loss 0.012823313474655151; train accuracy 100.0; test loss 0.07030372321605682; test accuracy 97.86999821662903; alpha 0.0222662484609674; mu 0.8\n",
      "Step 350; train loss 0.05454607680439949; train accuracy 98.4375; test loss 0.07344353199005127; test accuracy 97.75999784469604; alpha 0.021995293510729184; mu 0.8\n",
      "Step 400; train loss 0.10789620131254196; train accuracy 96.875; test loss 0.07108815014362335; test accuracy 97.79000282287598; alpha 0.02173399540921557; mu 0.8\n",
      "EPOCH  6  : ##########\n",
      "Step 0; train loss 0.021065780892968178; train accuracy 98.4375; test loss 0.07081539183855057; test accuracy 97.82000184059143; alpha 0.021586644588817278; mu 0.8\n",
      "Step 50; train loss 0.011681677773594856; train accuracy 100.0; test loss 0.07464136183261871; test accuracy 97.75999784469604; alpha 0.021339479988815996; mu 0.8\n",
      "Step 100; train loss 0.024457398802042007; train accuracy 99.21875; test loss 0.0727066844701767; test accuracy 97.82999753952026; alpha 0.021100615513931942; mu 0.8\n",
      "Step 150; train loss 0.008052695542573929; train accuracy 100.0; test loss 0.07205405831336975; test accuracy 97.79000282287598; alpha 0.020869596778242055; mu 0.8\n",
      "Step 200; train loss 0.07156576216220856; train accuracy 96.875; test loss 0.07159411907196045; test accuracy 97.86999821662903; alpha 0.02064600347538335; mu 0.8\n",
      "Step 250; train loss 0.028377380222082138; train accuracy 100.0; test loss 0.07336701452732086; test accuracy 97.65999913215637; alpha 0.020429446161135924; mu 0.8\n",
      "Step 300; train loss 0.008942247368395329; train accuracy 100.0; test loss 0.06900147348642349; test accuracy 97.86999821662903; alpha 0.020219563399637347; mu 0.8\n",
      "Step 350; train loss 0.014394694939255714; train accuracy 100.0; test loss 0.06970815360546112; test accuracy 97.94999957084656; alpha 0.02001601922563589; mu 0.8\n",
      "Step 400; train loss 0.04486027732491493; train accuracy 98.4375; test loss 0.07153879106044769; test accuracy 97.78000116348267; alpha 0.01981850088223545; mu 0.8\n",
      "EPOCH  7  : ##########\n",
      "Step 0; train loss 0.020475968718528748; train accuracy 100.0; test loss 0.07058439403772354; test accuracy 97.89000153541565; alpha 0.019706585563285865; mu 0.8\n",
      "Step 50; train loss 0.005992515478283167; train accuracy 100.0; test loss 0.07262962311506271; test accuracy 97.9200005531311; alpha 0.019518001458970664; mu 0.8\n",
      "Step 100; train loss 0.028357887640595436; train accuracy 98.4375; test loss 0.07332335412502289; test accuracy 97.8600025177002; alpha 0.019334729780913273; mu 0.8\n",
      "Step 150; train loss 0.03315453231334686; train accuracy 99.21875; test loss 0.07367102056741714; test accuracy 97.83999919891357; alpha 0.019156525704423027; mu 0.8\n",
      "Step 200; train loss 0.04098548740148544; train accuracy 98.4375; test loss 0.07389531284570694; test accuracy 97.96000123023987; alpha 0.01898315991504998; mu 0.8\n",
      "Step 250; train loss 0.010635139420628548; train accuracy 100.0; test loss 0.07038476318120956; test accuracy 98.00999760627747; alpha 0.018814417367671945; mu 0.8\n",
      "Step 300; train loss 0.013377384282648563; train accuracy 100.0; test loss 0.06891180574893951; test accuracy 97.85000085830688; alpha 0.018650096164806278; mu 0.8\n",
      "Step 350; train loss 0.019697409123182297; train accuracy 100.0; test loss 0.07270139455795288; test accuracy 97.93999791145325; alpha 0.018490006540840973; mu 0.8\n",
      "Step 400; train loss 0.006477605551481247; train accuracy 100.0; test loss 0.07105118036270142; test accuracy 97.82000184059143; alpha 0.018333969940564226; mu 0.8\n",
      "EPOCH  8  : ##########\n",
      "Step 0; train loss 0.004019545391201973; train accuracy 100.0; test loss 0.06965986639261246; test accuracy 97.96000123023987; alpha 0.01824525912922067; mu 0.8\n",
      "Step 50; train loss 0.049979038536548615; train accuracy 98.4375; test loss 0.06838104128837585; test accuracy 97.9099988937378; alpha 0.018095287334182187; mu 0.8\n",
      "Step 100; train loss 0.004196287132799625; train accuracy 100.0; test loss 0.07042872160673141; test accuracy 97.93000221252441; alpha 0.017948953965443454; mu 0.8\n",
      "Step 150; train loss 0.03344867751002312; train accuracy 98.4375; test loss 0.0694391205906868; test accuracy 97.9200005531311; alpha 0.017806114244894065; mu 0.8\n",
      "Step 200; train loss 0.00911380723118782; train accuracy 100.0; test loss 0.07214044034481049; test accuracy 97.93999791145325; alpha 0.017666631333439334; mu 0.8\n",
      "Step 250; train loss 0.006400315091013908; train accuracy 100.0; test loss 0.07063949108123779; test accuracy 97.94999957084656; alpha 0.0175303757799037; mu 0.8\n",
      "Step 300; train loss 0.007799960672855377; train accuracy 100.0; test loss 0.07049103826284409; test accuracy 97.93999791145325; alpha 0.017397225015980525; mu 0.8\n",
      "Step 350; train loss 0.014211343601346016; train accuracy 100.0; test loss 0.06935445219278336; test accuracy 97.99000024795532; alpha 0.017267062892749267; mu 0.8\n",
      "Step 400; train loss 0.00685538537800312; train accuracy 100.0; test loss 0.07206058502197266; test accuracy 97.9200005531311; alpha 0.017139779254776524; mu 0.8\n",
      "EPOCH  9  : ##########\n",
      "Step 0; train loss 0.008335370570421219; train accuracy 100.0; test loss 0.07387223094701767; test accuracy 97.82999753952026; alpha 0.0170672322461873; mu 0.8\n",
      "Step 50; train loss 0.025113530457019806; train accuracy 98.4375; test loss 0.07227164506912231; test accuracy 97.93999791145325; alpha 0.01694428559251163; mu 0.8\n",
      "Step 100; train loss 0.01530628651380539; train accuracy 100.0; test loss 0.07008100301027298; test accuracy 98.00999760627747; alpha 0.016823958224413904; mu 0.8\n",
      "Step 150; train loss 0.006035946309566498; train accuracy 100.0; test loss 0.07486608624458313; test accuracy 97.89000153541565; alpha 0.01670615844038759; mu 0.8\n",
      "Step 200; train loss 0.020126517862081528; train accuracy 99.21875; test loss 0.06982778012752533; test accuracy 98.0400025844574; alpha 0.016590798971560294; mu 0.8\n",
      "Step 250; train loss 0.006877122446894646; train accuracy 100.0; test loss 0.06918095052242279; test accuracy 98.00000190734863; alpha 0.016477796709963355; mu 0.8\n",
      "Step 300; train loss 0.008649539202451706; train accuracy 100.0; test loss 0.06762795150279999; test accuracy 98.05999994277954; alpha 0.016367072456887358; mu 0.8\n",
      "Step 350; train loss 0.0378713458776474; train accuracy 99.21875; test loss 0.07067133486270905; test accuracy 97.89999723434448; alpha 0.016258550689592154; mu 0.8\n",
      "Step 400; train loss 0.01645830273628235; train accuracy 99.21875; test loss 0.07102509588003159; test accuracy 97.93999791145325; alpha 0.01615215934480992; mu 0.8\n",
      "EPOCH  10  : ##########\n",
      "Step 0; train loss 0.004518094938248396; train accuracy 100.0; test loss 0.07255516201257706; test accuracy 97.93999791145325; alpha 0.01609140128253687; mu 0.8\n",
      "Step 50; train loss 0.01570904068648815; train accuracy 99.21875; test loss 0.07063254714012146; test accuracy 98.00000190734863; alpha 0.015988236984776985; mu 0.8\n",
      "Step 100; train loss 0.00908665545284748; train accuracy 100.0; test loss 0.06907886266708374; test accuracy 97.96000123023987; alpha 0.01588703178380234; mu 0.8\n",
      "Step 150; train loss 0.0027085887268185616; train accuracy 100.0; test loss 0.07039353996515274; test accuracy 98.00000190734863; alpha 0.015787724448766815; mu 0.8\n",
      "Step 200; train loss 0.004704649560153484; train accuracy 100.0; test loss 0.07061494886875153; test accuracy 97.99000024795532; alpha 0.015690256395005604; mu 0.8\n",
      "Step 250; train loss 0.018581900745630264; train accuracy 99.21875; test loss 0.06974022835493088; test accuracy 97.93000221252441; alpha 0.015594571538795133; mu 0.8\n",
      "Step 300; train loss 0.014697987586259842; train accuracy 99.21875; test loss 0.06907231360673904; test accuracy 97.94999957084656; alpha 0.015500616161738888; mu 0.8\n",
      "Step 350; train loss 0.009200973436236382; train accuracy 100.0; test loss 0.06907105445861816; test accuracy 97.96000123023987; alpha 0.015408338784034142; mu 0.8\n",
      "Step 400; train loss 0.026971224695444107; train accuracy 99.21875; test loss 0.07177136838436127; test accuracy 97.89999723434448; alpha 0.015317690045940371; mu 0.8\n",
      "Initial Error of  oLBFGS  :  2.6321366\n",
      "EPOCH  1  : ##########\n",
      "Step 0; train loss 1.292008399963379; train accuracy 67.96875; test loss 1.6671656370162964; test accuracy 44.850000739097595; alpha 0.8951048951048951; mu 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tensorflow-1.15.2/python3.7/tensorflow_core/contrib/opt/python/training/external_optimizer.py:402: OptimizeWarning: Unknown solver options: Hk_mat, muk\n",
      "  result = scipy.optimize.minimize(*minimize_args, **minimize_kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 50; train loss 0.17940717935562134; train accuracy 96.875; test loss 0.25985050201416016; test accuracy 93.14000010490417; alpha 0.1614123581336696; mu 0\n",
      "Step 100; train loss 0.21512523293495178; train accuracy 93.75; test loss 0.22082538902759552; test accuracy 93.84999871253967; alpha 0.0887040887040887; mu 0\n",
      "Step 150; train loss 0.18039989471435547; train accuracy 96.09375; test loss 0.19883307814598083; test accuracy 94.48999762535095; alpha 0.06115623506927855; mu 0\n",
      "Step 200; train loss 0.2612343430519104; train accuracy 90.625; test loss 0.18702177703380585; test accuracy 94.91999745368958; alpha 0.04666423623769595; mu 0\n",
      "Step 250; train loss 0.2069089710712433; train accuracy 93.75; test loss 0.17999547719955444; test accuracy 95.06000280380249; alpha 0.03772472737989979; mu 0\n",
      "Step 300; train loss 0.14704719185829163; train accuracy 96.875; test loss 0.17514127492904663; test accuracy 95.16000151634216; alpha 0.03165965866930497; mu 0\n",
      "Step 350; train loss 0.2417517453432083; train accuracy 92.96875; test loss 0.16989058256149292; test accuracy 95.1799988746643; alpha 0.02727466439377797; mu 0\n",
      "Step 400; train loss 0.17698873579502106; train accuracy 96.09375; test loss 0.16509252786636353; test accuracy 95.38000226020813; alpha 0.02395657870110425; mu 0\n",
      "EPOCH  2  : ##########\n",
      "Step 0; train loss 0.1930760145187378; train accuracy 95.3125; test loss 0.16297881305217743; test accuracy 95.39999961853027; alpha 0.02237762237762238; mu 0\n",
      "Step 50; train loss 0.14813129603862762; train accuracy 95.3125; test loss 0.1608346700668335; test accuracy 95.4200029373169; alpha 0.020094191522762952; mu 0\n",
      "Step 100; train loss 0.10636688023805618; train accuracy 97.65625; test loss 0.15860547125339508; test accuracy 95.49000263214111; alpha 0.018233618233618232; mu 0\n",
      "Step 150; train loss 0.127531498670578; train accuracy 96.09375; test loss 0.15617018938064575; test accuracy 95.56999802589417; alpha 0.016688396349413298; mu 0\n",
      "Step 200; train loss 0.06853921711444855; train accuracy 99.21875; test loss 0.15459135174751282; test accuracy 95.74000239372253; alpha 0.015384615384615385; mu 0\n",
      "Step 250; train loss 0.1289442628622055; train accuracy 96.875; test loss 0.15397189557552338; test accuracy 95.67000269889832; alpha 0.014269788182831662; mu 0\n",
      "Step 300; train loss 0.12585309147834778; train accuracy 96.875; test loss 0.151884526014328; test accuracy 95.67000269889832; alpha 0.013305613305613306; mu 0\n",
      "Step 350; train loss 0.1536397635936737; train accuracy 95.3125; test loss 0.15009646117687225; test accuracy 95.81999778747559; alpha 0.0124634858812074; mu 0\n",
      "Step 400; train loss 0.15172968804836273; train accuracy 96.09375; test loss 0.14885269105434418; test accuracy 95.80000042915344; alpha 0.011721611721611722; mu 0\n",
      "EPOCH  3  : ##########\n",
      "Step 0; train loss 0.13616348803043365; train accuracy 98.4375; test loss 0.14789582788944244; test accuracy 95.8899974822998; alpha 0.011330441710188547; mu 0\n",
      "Step 50; train loss 0.12887844443321228; train accuracy 96.875; test loss 0.14650505781173706; test accuracy 95.88000178337097; alpha 0.010713986774922576; mu 0\n",
      "Step 100; train loss 0.17970672249794006; train accuracy 94.53125; test loss 0.14516618847846985; test accuracy 95.96999883651733; alpha 0.01016114948003493; mu 0\n",
      "Step 150; train loss 0.12948839366436005; train accuracy 96.875; test loss 0.1440562903881073; test accuracy 95.95999717712402; alpha 0.009662565109081303; mu 0\n",
      "Step 200; train loss 0.1078997552394867; train accuracy 96.875; test loss 0.14361976087093353; test accuracy 96.03000283241272; alpha 0.009210620997337556; mu 0\n",
      "Step 250; train loss 0.06724922358989716; train accuracy 97.65625; test loss 0.1430341601371765; test accuracy 96.03000283241272; alpha 0.008799065099333196; mu 0\n",
      "Step 300; train loss 0.10123434662818909; train accuracy 97.65625; test loss 0.14220573008060455; test accuracy 96.06000185012817; alpha 0.008422715009541358; mu 0\n",
      "Step 350; train loss 0.10448463261127472; train accuracy 96.875; test loss 0.14197193086147308; test accuracy 95.99999785423279; alpha 0.008077238594055658; mu 0\n",
      "Step 400; train loss 0.14760974049568176; train accuracy 97.65625; test loss 0.1412082463502884; test accuracy 96.0099995136261; alpha 0.007758986482390737; mu 0\n",
      "EPOCH  4  : ##########\n",
      "Step 0; train loss 0.1434602588415146; train accuracy 96.09375; test loss 0.14096930623054504; test accuracy 96.069997549057; alpha 0.007585634704278772; mu 0\n",
      "Step 50; train loss 0.11979690194129944; train accuracy 96.09375; test loss 0.1411670744419098; test accuracy 96.03999853134155; alpha 0.007304268431864872; mu 0\n",
      "Step 100; train loss 0.09711475670337677; train accuracy 96.875; test loss 0.14019900560379028; test accuracy 96.069997549057; alpha 0.00704302850225597; mu 0\n",
      "Step 150; train loss 0.19882021844387054; train accuracy 93.75; test loss 0.1398596614599228; test accuracy 96.10999822616577; alpha 0.006799830004249894; mu 0\n",
      "Step 200; train loss 0.12727439403533936; train accuracy 94.53125; test loss 0.13928177952766418; test accuracy 96.09000086784363; alpha 0.006572866385950499; mu 0\n",
      "Step 250; train loss 0.12596827745437622; train accuracy 96.875; test loss 0.1385037899017334; test accuracy 96.10000252723694; alpha 0.006360564500099384; mu 0\n",
      "Step 300; train loss 0.08687643706798553; train accuracy 98.4375; test loss 0.13799968361854553; test accuracy 96.13999724388123; alpha 0.006161548088957351; mu 0\n",
      "Step 350; train loss 0.11766606569290161; train accuracy 97.65625; test loss 0.137591153383255; test accuracy 96.14999890327454; alpha 0.00597460791635549; mu 0\n",
      "Step 400; train loss 0.1449948400259018; train accuracy 96.875; test loss 0.13720571994781494; test accuracy 96.13999724388123; alpha 0.00579867717676905; mu 0\n",
      "EPOCH  5  : ##########\n",
      "Step 0; train loss 0.07301239669322968; train accuracy 99.21875; test loss 0.1369822770357132; test accuracy 96.20000123977661; alpha 0.005701305064362389; mu 0\n",
      "Step 50; train loss 0.17615865170955658; train accuracy 92.96875; test loss 0.13631515204906464; test accuracy 96.1899995803833; alpha 0.005540885675944764; mu 0\n",
      "Step 100; train loss 0.11138893663883209; train accuracy 95.3125; test loss 0.13585302233695984; test accuracy 96.1899995803833; alpha 0.005389246768557113; mu 0\n",
      "Step 150; train loss 0.1066017597913742; train accuracy 97.65625; test loss 0.1354495882987976; test accuracy 96.21000289916992; alpha 0.005245686652186386; mu 0\n",
      "Step 200; train loss 0.058183249086141586; train accuracy 100.0; test loss 0.13528737425804138; test accuracy 96.20000123977661; alpha 0.005109576464013413; mu 0\n",
      "Step 250; train loss 0.11590445041656494; train accuracy 97.65625; test loss 0.1350640207529068; test accuracy 96.17000222206116; alpha 0.00498035095910665; mu 0\n",
      "Step 300; train loss 0.11246931552886963; train accuracy 97.65625; test loss 0.1347394436597824; test accuracy 96.20000123977661; alpha 0.004857500664111419; mu 0\n",
      "Step 350; train loss 0.15866190195083618; train accuracy 96.09375; test loss 0.1344500184059143; test accuracy 96.21999859809875; alpha 0.004740565164253177; mu 0\n",
      "Step 400; train loss 0.14675211906433105; train accuracy 96.875; test loss 0.1341109424829483; test accuracy 96.24999761581421; alpha 0.004629127337166829; mu 0\n",
      "EPOCH  6  : ##########\n",
      "Step 0; train loss 0.12220682203769684; train accuracy 97.65625; test loss 0.1338924616575241; test accuracy 96.24999761581421; alpha 0.004566861709718853; mu 0\n",
      "Step 50; train loss 0.10327096283435822; train accuracy 96.875; test loss 0.13346467912197113; test accuracy 96.25999927520752; alpha 0.004463351698165842; mu 0\n",
      "Step 100; train loss 0.08901989459991455; train accuracy 96.875; test loss 0.1332288533449173; test accuracy 96.27000093460083; alpha 0.0043644298963447905; mu 0\n",
      "Step 150; train loss 0.06888428330421448; train accuracy 100.0; test loss 0.1330857276916504; test accuracy 96.24999761581421; alpha 0.0042697978517579555; mu 0\n",
      "Step 200; train loss 0.19090045988559723; train accuracy 95.3125; test loss 0.13279841840267181; test accuracy 96.25999927520752; alpha 0.004179182447433721; mu 0\n",
      "Step 250; train loss 0.14199742674827576; train accuracy 94.53125; test loss 0.13266971707344055; test accuracy 96.25999927520752; alpha 0.004092333269390626; mu 0\n",
      "Step 300; train loss 0.07861565798521042; train accuracy 98.4375; test loss 0.1321190446615219; test accuracy 96.28999829292297; alpha 0.004009020295665247; mu 0\n",
      "Step 350; train loss 0.1364617645740509; train accuracy 96.875; test loss 0.1318380981683731; test accuracy 96.24999761581421; alpha 0.003929031861992756; mu 0\n",
      "Step 400; train loss 0.15119263529777527; train accuracy 95.3125; test loss 0.1315573900938034; test accuracy 96.24999761581421; alpha 0.0038521728662573736; mu 0\n",
      "EPOCH  7  : ##########\n",
      "Step 0; train loss 0.19297024607658386; train accuracy 92.96875; test loss 0.13145394623279572; test accuracy 96.25999927520752; alpha 0.0038089570004463625; mu 0\n",
      "Step 50; train loss 0.056776709854602814; train accuracy 99.21875; test loss 0.13137558102607727; test accuracy 96.28000259399414; alpha 0.003736680776528974; mu 0\n",
      "Step 100; train loss 0.13831418752670288; train accuracy 96.09375; test loss 0.1313696950674057; test accuracy 96.27000093460083; alpha 0.0036670964045265723; mu 0\n",
      "Step 150; train loss 0.11484768986701965; train accuracy 95.3125; test loss 0.13113492727279663; test accuracy 96.25999927520752; alpha 0.00360005625087892; mu 0\n",
      "Step 200; train loss 0.1774488091468811; train accuracy 94.53125; test loss 0.13088156282901764; test accuracy 96.25999927520752; alpha 0.0035354232840767853; mu 0\n",
      "Step 250; train loss 0.11691330373287201; train accuracy 96.09375; test loss 0.13055221736431122; test accuracy 96.27000093460083; alpha 0.0034730701397368063; mu 0\n",
      "Step 300; train loss 0.1283690333366394; train accuracy 96.875; test loss 0.13011616468429565; test accuracy 96.28999829292297; alpha 0.003412878282895614; mu 0\n",
      "Step 350; train loss 0.131708562374115; train accuracy 97.65625; test loss 0.129912868142128; test accuracy 96.29999995231628; alpha 0.0033547372559297605; mu 0\n",
      "Step 400; train loss 0.05390389636158943; train accuracy 99.21875; test loss 0.12968139350414276; test accuracy 96.28999829292297; alpha 0.00329854400206159; mu 0\n",
      "EPOCH  8  : ##########\n",
      "Step 0; train loss 0.07617737352848053; train accuracy 97.65625; test loss 0.12959764897823334; test accuracy 96.29999995231628; alpha 0.003266806186514216; mu 0\n",
      "Step 50; train loss 0.13535626232624054; train accuracy 96.09375; test loss 0.12938173115253448; test accuracy 96.29999995231628; alpha 0.0032134966860815424; mu 0\n",
      "Step 100; train loss 0.1059742271900177; train accuracy 96.875; test loss 0.12910814583301544; test accuracy 96.28999829292297; alpha 0.003161899115656341; mu 0\n",
      "Step 150; train loss 0.0997752696275711; train accuracy 96.875; test loss 0.12919005751609802; test accuracy 96.3100016117096; alpha 0.0031119323154721384; mu 0\n",
      "Step 200; train loss 0.1505715698003769; train accuracy 94.53125; test loss 0.1289137303829193; test accuracy 96.29999995231628; alpha 0.00306352017615241; mu 0\n",
      "Step 250; train loss 0.0876660868525505; train accuracy 96.875; test loss 0.12880487740039825; test accuracy 96.31999731063843; alpha 0.0030165912518853697; mu 0\n",
      "Step 300; train loss 0.09894490987062454; train accuracy 96.875; test loss 0.12861205637454987; test accuracy 96.29999995231628; alpha 0.0029710784086161273; mu 0\n",
      "Step 350; train loss 0.10878531634807587; train accuracy 96.09375; test loss 0.12833084166049957; test accuracy 96.3100016117096; alpha 0.0029269185036129154; mu 0\n",
      "Step 400; train loss 0.11069945991039276; train accuracy 98.4375; test loss 0.12813088297843933; test accuracy 96.3100016117096; alpha 0.0028840520931909335; mu 0\n",
      "EPOCH  9  : ##########\n",
      "Step 0; train loss 0.13785187900066376; train accuracy 96.09375; test loss 0.1280389130115509; test accuracy 96.29999995231628; alpha 0.002859760048258451; mu 0\n",
      "Step 50; train loss 0.11940065026283264; train accuracy 96.09375; test loss 0.12799525260925293; test accuracy 96.31999731063843; alpha 0.002818824462111036; mu 0\n",
      "Step 100; train loss 0.09901437163352966; train accuracy 96.875; test loss 0.12788134813308716; test accuracy 96.3100016117096; alpha 0.002779044269306759; mu 0\n",
      "Step 150; train loss 0.13389426469802856; train accuracy 97.65625; test loss 0.12779584527015686; test accuracy 96.32999897003174; alpha 0.0027403712346656963; mu 0\n",
      "Step 200; train loss 0.10093343257904053; train accuracy 99.21875; test loss 0.1275232881307602; test accuracy 96.31999731063843; alpha 0.0027027597711100316; mu 0\n",
      "Step 250; train loss 0.11994011700153351; train accuracy 98.4375; test loss 0.12718747556209564; test accuracy 96.31999731063843; alpha 0.002666166760399092; mu 0\n",
      "Step 300; train loss 0.1430748999118805; train accuracy 96.09375; test loss 0.12711486220359802; test accuracy 96.31999731063843; alpha 0.002630551388232393; mu 0\n",
      "Step 350; train loss 0.12854596972465515; train accuracy 96.875; test loss 0.1269809603691101; test accuracy 96.32999897003174; alpha 0.0025958749923948978; mu 0\n",
      "Step 400; train loss 0.16311919689178467; train accuracy 94.53125; test loss 0.12691354751586914; test accuracy 96.32999897003174; alpha 0.0025621009227566605; mu 0\n",
      "EPOCH  10  : ##########\n",
      "Step 0; train loss 0.08862538635730743; train accuracy 97.65625; test loss 0.1268414556980133; test accuracy 96.34000062942505; alpha 0.0025429116338207248; mu 0\n",
      "Step 50; train loss 0.08009426295757294; train accuracy 96.875; test loss 0.1267230212688446; test accuracy 96.35000228881836; alpha 0.0025104930765308124; mu 0\n",
      "Step 100; train loss 0.12565425038337708; train accuracy 95.3125; test loss 0.12648175656795502; test accuracy 96.35999798774719; alpha 0.002478890696413355; mu 0\n",
      "Step 150; train loss 0.11729493737220764; train accuracy 96.09375; test loss 0.12647385895252228; test accuracy 96.38000130653381; alpha 0.0024480740542401408; mu 0\n",
      "Step 200; train loss 0.13469529151916504; train accuracy 97.65625; test loss 0.12627726793289185; test accuracy 96.34000062942505; alpha 0.0024180142058334592; mu 0\n",
      "Step 250; train loss 0.1386902928352356; train accuracy 96.875; test loss 0.12615422904491425; test accuracy 96.32999897003174; alpha 0.002388683611391035; mu 0\n",
      "Step 300; train loss 0.09481821209192276; train accuracy 97.65625; test loss 0.1260330080986023; test accuracy 96.35000228881836; alpha 0.0023600560513312194; mu 0\n",
      "Step 350; train loss 0.1317235827445984; train accuracy 96.875; test loss 0.12590427696704865; test accuracy 96.35000228881836; alpha 0.0023321065481179174; mu 0\n",
      "Step 400; train loss 0.11696184426546097; train accuracy 96.875; test loss 0.1257748156785965; test accuracy 96.3699996471405; alpha 0.002304811293575339; mu 0\n",
      "Initial Error of  Adam  :  2.6321366\n",
      "EPOCH  1  : ##########\n",
      "Step 0; train loss 2.7136802673339844; train accuracy 4.6875; test loss 2.603992462158203; test accuracy 7.540000230073929; alpha 0.9; mu 0\n",
      "Step 50; train loss 1.6714789867401123; train accuracy 53.125; test loss 1.6735543012619019; test accuracy 47.690001130104065; alpha 0.9; mu 0\n",
      "Step 100; train loss 1.2814662456512451; train accuracy 71.09375; test loss 1.2512444257736206; test accuracy 66.54999852180481; alpha 0.9; mu 0\n",
      "Step 150; train loss 1.0501000881195068; train accuracy 76.5625; test loss 1.02001953125; test accuracy 76.12000107765198; alpha 0.9; mu 0\n",
      "Step 200; train loss 0.9203442335128784; train accuracy 82.8125; test loss 0.8723857402801514; test accuracy 81.26000165939331; alpha 0.9; mu 0\n",
      "Step 250; train loss 0.8814007043838501; train accuracy 77.34375; test loss 0.7671793699264526; test accuracy 84.00999903678894; alpha 0.9; mu 0\n",
      "Step 300; train loss 0.7629205584526062; train accuracy 83.59375; test loss 0.6900061368942261; test accuracy 86.04999780654907; alpha 0.9; mu 0\n",
      "Step 350; train loss 0.7050781846046448; train accuracy 85.15625; test loss 0.6290303468704224; test accuracy 87.23999857902527; alpha 0.9; mu 0\n",
      "Step 400; train loss 0.5732313394546509; train accuracy 87.5; test loss 0.5800828337669373; test accuracy 88.30999732017517; alpha 0.9; mu 0\n",
      "EPOCH  2  : ##########\n",
      "Step 0; train loss 0.6566024422645569; train accuracy 81.25; test loss 0.5551580786705017; test accuracy 88.80000114440918; alpha 0.81; mu 0\n",
      "Step 50; train loss 0.5703529715538025; train accuracy 89.84375; test loss 0.5196942090988159; test accuracy 89.30000066757202; alpha 0.81; mu 0\n",
      "Step 100; train loss 0.4770853519439697; train accuracy 91.40625; test loss 0.48881641030311584; test accuracy 90.04999995231628; alpha 0.81; mu 0\n",
      "Step 150; train loss 0.45534420013427734; train accuracy 92.96875; test loss 0.4619430601596832; test accuracy 90.57999849319458; alpha 0.81; mu 0\n",
      "Step 200; train loss 0.3845801055431366; train accuracy 93.75; test loss 0.4381459951400757; test accuracy 91.06000065803528; alpha 0.81; mu 0\n",
      "Step 250; train loss 0.3963930010795593; train accuracy 92.96875; test loss 0.4179838001728058; test accuracy 91.4900004863739; alpha 0.81; mu 0\n",
      "Step 300; train loss 0.4210468530654907; train accuracy 90.625; test loss 0.3993164598941803; test accuracy 91.68000221252441; alpha 0.81; mu 0\n",
      "Step 350; train loss 0.44426435232162476; train accuracy 91.40625; test loss 0.3818489611148834; test accuracy 92.17000007629395; alpha 0.81; mu 0\n",
      "Step 400; train loss 0.41314202547073364; train accuracy 92.96875; test loss 0.3670578896999359; test accuracy 92.33999848365784; alpha 0.81; mu 0\n",
      "EPOCH  3  : ##########\n",
      "Step 0; train loss 0.36665552854537964; train accuracy 92.96875; test loss 0.3586030900478363; test accuracy 92.48999953269958; alpha 0.7290000000000001; mu 0\n",
      "Step 50; train loss 0.36962512135505676; train accuracy 95.3125; test loss 0.34517115354537964; test accuracy 92.76000261306763; alpha 0.7290000000000001; mu 0\n",
      "Step 100; train loss 0.4339403510093689; train accuracy 84.375; test loss 0.3335498869419098; test accuracy 92.96000003814697; alpha 0.7290000000000001; mu 0\n",
      "Step 150; train loss 0.34860289096832275; train accuracy 92.96875; test loss 0.3225545287132263; test accuracy 93.16999912261963; alpha 0.7290000000000001; mu 0\n",
      "Step 200; train loss 0.32704034447669983; train accuracy 90.625; test loss 0.3126954436302185; test accuracy 93.3899998664856; alpha 0.7290000000000001; mu 0\n",
      "Step 250; train loss 0.2111625075340271; train accuracy 98.4375; test loss 0.3040565550327301; test accuracy 93.44000220298767; alpha 0.7290000000000001; mu 0\n",
      "Step 300; train loss 0.25584277510643005; train accuracy 94.53125; test loss 0.29530069231987; test accuracy 93.58000159263611; alpha 0.7290000000000001; mu 0\n",
      "Step 350; train loss 0.28196510672569275; train accuracy 92.1875; test loss 0.28759312629699707; test accuracy 93.70999932289124; alpha 0.7290000000000001; mu 0\n",
      "Step 400; train loss 0.3212539553642273; train accuracy 92.96875; test loss 0.28029826283454895; test accuracy 93.77999901771545; alpha 0.7290000000000001; mu 0\n",
      "EPOCH  4  : ##########\n",
      "Step 0; train loss 0.30490219593048096; train accuracy 95.3125; test loss 0.27590060234069824; test accuracy 93.91999840736389; alpha 0.6561000000000001; mu 0\n",
      "Step 50; train loss 0.2599581480026245; train accuracy 94.53125; test loss 0.2700437009334564; test accuracy 94.04000043869019; alpha 0.6561000000000001; mu 0\n",
      "Step 100; train loss 0.23730435967445374; train accuracy 95.3125; test loss 0.26312005519866943; test accuracy 94.13999915122986; alpha 0.6561000000000001; mu 0\n",
      "Step 150; train loss 0.3137866258621216; train accuracy 92.1875; test loss 0.25726574659347534; test accuracy 94.27000284194946; alpha 0.6561000000000001; mu 0\n",
      "Step 200; train loss 0.2537853717803955; train accuracy 92.96875; test loss 0.2511325180530548; test accuracy 94.37000155448914; alpha 0.6561000000000001; mu 0\n",
      "Step 250; train loss 0.2504441738128662; train accuracy 95.3125; test loss 0.2450288087129593; test accuracy 94.42999958992004; alpha 0.6561000000000001; mu 0\n",
      "Step 300; train loss 0.1953294575214386; train accuracy 96.09375; test loss 0.23912793397903442; test accuracy 94.47000026702881; alpha 0.6561000000000001; mu 0\n",
      "Step 350; train loss 0.27870598435401917; train accuracy 94.53125; test loss 0.2339763194322586; test accuracy 94.66999769210815; alpha 0.6561000000000001; mu 0\n",
      "Step 400; train loss 0.26925718784332275; train accuracy 92.1875; test loss 0.22920964658260345; test accuracy 94.67999935150146; alpha 0.6561000000000001; mu 0\n",
      "EPOCH  5  : ##########\n",
      "Step 0; train loss 0.16714397072792053; train accuracy 97.65625; test loss 0.22667910158634186; test accuracy 94.67999935150146; alpha 0.5904900000000002; mu 0\n",
      "Step 50; train loss 0.2649034261703491; train accuracy 92.1875; test loss 0.22177134454250336; test accuracy 94.85999941825867; alpha 0.5904900000000002; mu 0\n",
      "Step 100; train loss 0.18625426292419434; train accuracy 96.09375; test loss 0.21767570078372955; test accuracy 94.88000273704529; alpha 0.5904900000000002; mu 0\n",
      "Step 150; train loss 0.18190649151802063; train accuracy 95.3125; test loss 0.21390604972839355; test accuracy 94.91000175476074; alpha 0.5904900000000002; mu 0\n",
      "Step 200; train loss 0.14469274878501892; train accuracy 97.65625; test loss 0.21024367213249207; test accuracy 94.9999988079071; alpha 0.5904900000000002; mu 0\n",
      "Step 250; train loss 0.1903122216463089; train accuracy 94.53125; test loss 0.2066553235054016; test accuracy 94.98000144958496; alpha 0.5904900000000002; mu 0\n",
      "Step 300; train loss 0.20500287413597107; train accuracy 94.53125; test loss 0.20323725044727325; test accuracy 95.02999782562256; alpha 0.5904900000000002; mu 0\n",
      "Step 350; train loss 0.2105526328086853; train accuracy 95.3125; test loss 0.20010972023010254; test accuracy 95.06999850273132; alpha 0.5904900000000002; mu 0\n",
      "Step 400; train loss 0.2490987777709961; train accuracy 95.3125; test loss 0.19566386938095093; test accuracy 95.20000219345093; alpha 0.5904900000000002; mu 0\n",
      "EPOCH  6  : ##########\n",
      "Step 0; train loss 0.19925133883953094; train accuracy 93.75; test loss 0.19384051859378815; test accuracy 95.21999955177307; alpha 0.5314410000000002; mu 0\n",
      "Step 50; train loss 0.16558173298835754; train accuracy 96.09375; test loss 0.19040094316005707; test accuracy 95.24000287055969; alpha 0.5314410000000002; mu 0\n",
      "Step 100; train loss 0.14531242847442627; train accuracy 96.09375; test loss 0.18800674378871918; test accuracy 95.39999961853027; alpha 0.5314410000000002; mu 0\n",
      "Step 150; train loss 0.14819400012493134; train accuracy 97.65625; test loss 0.18555691838264465; test accuracy 95.31999826431274; alpha 0.5314410000000002; mu 0\n",
      "Step 200; train loss 0.21606417000293732; train accuracy 95.3125; test loss 0.1825253814458847; test accuracy 95.38000226020813; alpha 0.5314410000000002; mu 0\n",
      "Step 250; train loss 0.19327843189239502; train accuracy 92.96875; test loss 0.18045398592948914; test accuracy 95.49000263214111; alpha 0.5314410000000002; mu 0\n",
      "Step 300; train loss 0.12972331047058105; train accuracy 96.875; test loss 0.17664293944835663; test accuracy 95.660001039505; alpha 0.5314410000000002; mu 0\n",
      "Step 350; train loss 0.21694254875183105; train accuracy 93.75; test loss 0.17339062690734863; test accuracy 95.7099974155426; alpha 0.5314410000000002; mu 0\n",
      "Step 400; train loss 0.2007872462272644; train accuracy 94.53125; test loss 0.1712067872285843; test accuracy 95.75999975204468; alpha 0.5314410000000002; mu 0\n",
      "EPOCH  7  : ##########\n",
      "Step 0; train loss 0.22820822894573212; train accuracy 93.75; test loss 0.16997911036014557; test accuracy 95.70000171661377; alpha 0.47829690000000014; mu 0\n",
      "Step 50; train loss 0.10785208642482758; train accuracy 97.65625; test loss 0.16806316375732422; test accuracy 95.71999907493591; alpha 0.47829690000000014; mu 0\n",
      "Step 100; train loss 0.18172259628772736; train accuracy 94.53125; test loss 0.16611510515213013; test accuracy 95.78999876976013; alpha 0.47829690000000014; mu 0\n",
      "Step 150; train loss 0.14703507721424103; train accuracy 95.3125; test loss 0.16366435587406158; test accuracy 95.91000080108643; alpha 0.47829690000000014; mu 0\n",
      "Step 200; train loss 0.2023942470550537; train accuracy 93.75; test loss 0.1610058844089508; test accuracy 95.91000080108643; alpha 0.47829690000000014; mu 0\n",
      "Step 250; train loss 0.17260870337486267; train accuracy 96.09375; test loss 0.15869460999965668; test accuracy 96.069997549057; alpha 0.47829690000000014; mu 0\n",
      "Step 300; train loss 0.15195852518081665; train accuracy 96.875; test loss 0.15633338689804077; test accuracy 95.99000215530396; alpha 0.47829690000000014; mu 0\n",
      "Step 350; train loss 0.16210968792438507; train accuracy 96.875; test loss 0.15522536635398865; test accuracy 96.10999822616577; alpha 0.47829690000000014; mu 0\n",
      "Step 400; train loss 0.09604859352111816; train accuracy 98.4375; test loss 0.15333546698093414; test accuracy 96.13000154495239; alpha 0.47829690000000014; mu 0\n",
      "EPOCH  8  : ##########\n",
      "Step 0; train loss 0.0957258865237236; train accuracy 97.65625; test loss 0.1519475132226944; test accuracy 96.17999792098999; alpha 0.43046721000000016; mu 0\n",
      "Step 50; train loss 0.14290285110473633; train accuracy 96.09375; test loss 0.15033353865146637; test accuracy 96.1899995803833; alpha 0.43046721000000016; mu 0\n",
      "Step 100; train loss 0.10869719833135605; train accuracy 96.875; test loss 0.14832012355327606; test accuracy 96.29999995231628; alpha 0.43046721000000016; mu 0\n",
      "Step 150; train loss 0.1238328218460083; train accuracy 97.65625; test loss 0.14730249345302582; test accuracy 96.24000191688538; alpha 0.43046721000000016; mu 0\n",
      "Step 200; train loss 0.15362074971199036; train accuracy 96.09375; test loss 0.14495980739593506; test accuracy 96.25999927520752; alpha 0.43046721000000016; mu 0\n",
      "Step 250; train loss 0.1130983829498291; train accuracy 96.875; test loss 0.1435507982969284; test accuracy 96.28000259399414; alpha 0.43046721000000016; mu 0\n",
      "Step 300; train loss 0.11697928607463837; train accuracy 96.09375; test loss 0.1421264410018921; test accuracy 96.31999731063843; alpha 0.43046721000000016; mu 0\n",
      "Step 350; train loss 0.10910318046808243; train accuracy 96.875; test loss 0.14063715934753418; test accuracy 96.42999768257141; alpha 0.43046721000000016; mu 0\n",
      "Step 400; train loss 0.12823496758937836; train accuracy 98.4375; test loss 0.1388140618801117; test accuracy 96.39999866485596; alpha 0.43046721000000016; mu 0\n",
      "EPOCH  9  : ##########\n",
      "Step 0; train loss 0.14875555038452148; train accuracy 94.53125; test loss 0.13829882442951202; test accuracy 96.42000198364258; alpha 0.38742048900000015; mu 0\n",
      "Step 50; train loss 0.11587115377187729; train accuracy 97.65625; test loss 0.13709674775600433; test accuracy 96.50999903678894; alpha 0.38742048900000015; mu 0\n",
      "Step 100; train loss 0.1144009456038475; train accuracy 97.65625; test loss 0.13576523959636688; test accuracy 96.49999737739563; alpha 0.38742048900000015; mu 0\n",
      "Step 150; train loss 0.13655492663383484; train accuracy 96.875; test loss 0.1342259794473648; test accuracy 96.53000235557556; alpha 0.38742048900000015; mu 0\n",
      "Step 200; train loss 0.10030480474233627; train accuracy 99.21875; test loss 0.13240106403827667; test accuracy 96.5499997138977; alpha 0.38742048900000015; mu 0\n",
      "Step 250; train loss 0.12072548270225525; train accuracy 97.65625; test loss 0.13028845191001892; test accuracy 96.60999774932861; alpha 0.38742048900000015; mu 0\n",
      "Step 300; train loss 0.135807067155838; train accuracy 96.875; test loss 0.12928462028503418; test accuracy 96.670001745224; alpha 0.38742048900000015; mu 0\n",
      "Step 350; train loss 0.13957872986793518; train accuracy 97.65625; test loss 0.12776069343090057; test accuracy 96.75999879837036; alpha 0.38742048900000015; mu 0\n",
      "Step 400; train loss 0.16766929626464844; train accuracy 96.09375; test loss 0.1273059993982315; test accuracy 96.68999910354614; alpha 0.38742048900000015; mu 0\n",
      "EPOCH  10  : ##########\n",
      "Step 0; train loss 0.09705010056495667; train accuracy 96.875; test loss 0.12676377594470978; test accuracy 96.64000272750854; alpha 0.34867844010000015; mu 0\n",
      "Step 50; train loss 0.08206029236316681; train accuracy 96.875; test loss 0.1256902515888214; test accuracy 96.64999842643738; alpha 0.34867844010000015; mu 0\n",
      "Step 100; train loss 0.10639242827892303; train accuracy 98.4375; test loss 0.12378197908401489; test accuracy 96.74000144004822; alpha 0.34867844010000015; mu 0\n",
      "Step 150; train loss 0.11151459813117981; train accuracy 97.65625; test loss 0.1229369044303894; test accuracy 96.74000144004822; alpha 0.34867844010000015; mu 0\n",
      "Step 200; train loss 0.10602286458015442; train accuracy 99.21875; test loss 0.12168582528829575; test accuracy 96.74999713897705; alpha 0.34867844010000015; mu 0\n",
      "Step 250; train loss 0.12951117753982544; train accuracy 97.65625; test loss 0.12111447751522064; test accuracy 96.78999781608582; alpha 0.34867844010000015; mu 0\n",
      "Step 300; train loss 0.10394084453582764; train accuracy 96.875; test loss 0.12044785171747208; test accuracy 96.79999947547913; alpha 0.34867844010000015; mu 0\n",
      "Step 350; train loss 0.12971648573875427; train accuracy 95.3125; test loss 0.11954370141029358; test accuracy 96.79999947547913; alpha 0.34867844010000015; mu 0\n",
      "Step 400; train loss 0.10894479602575302; train accuracy 97.65625; test loss 0.11860419064760208; test accuracy 96.85999751091003; alpha 0.34867844010000015; mu 0\n",
      "EPOCH  11  : ##########\n",
      "Step 0; train loss 0.11387782543897629; train accuracy 96.875; test loss 0.11780804395675659; test accuracy 96.86999917030334; alpha 0.31381059609000017; mu 0\n",
      "Step 50; train loss 0.0851064994931221; train accuracy 97.65625; test loss 0.1172046884894371; test accuracy 96.86999917030334; alpha 0.31381059609000017; mu 0\n",
      "Step 100; train loss 0.12663185596466064; train accuracy 97.65625; test loss 0.11619050055742264; test accuracy 96.84000015258789; alpha 0.31381059609000017; mu 0\n",
      "Step 150; train loss 0.06321922689676285; train accuracy 99.21875; test loss 0.11580201238393784; test accuracy 96.75999879837036; alpha 0.31381059609000017; mu 0\n",
      "Step 200; train loss 0.12545645236968994; train accuracy 95.3125; test loss 0.11481596529483795; test accuracy 96.95000052452087; alpha 0.31381059609000017; mu 0\n",
      "Step 250; train loss 0.09719105064868927; train accuracy 96.875; test loss 0.11319111287593842; test accuracy 96.96000218391418; alpha 0.31381059609000017; mu 0\n",
      "Step 300; train loss 0.10620678961277008; train accuracy 96.875; test loss 0.1117241233587265; test accuracy 97.00000286102295; alpha 0.31381059609000017; mu 0\n",
      "Step 350; train loss 0.1106966957449913; train accuracy 96.09375; test loss 0.11084091663360596; test accuracy 96.92999720573425; alpha 0.31381059609000017; mu 0\n",
      "Step 400; train loss 0.14489629864692688; train accuracy 95.3125; test loss 0.11101174354553223; test accuracy 97.02000021934509; alpha 0.31381059609000017; mu 0\n",
      "EPOCH  12  : ##########\n",
      "Step 0; train loss 0.07890668511390686; train accuracy 98.4375; test loss 0.11076079308986664; test accuracy 97.0300018787384; alpha 0.28242953648100017; mu 0\n",
      "Step 50; train loss 0.17536261677742004; train accuracy 96.09375; test loss 0.11033044755458832; test accuracy 97.02000021934509; alpha 0.28242953648100017; mu 0\n",
      "Step 100; train loss 0.13242055475711823; train accuracy 95.3125; test loss 0.10876709967851639; test accuracy 97.04999923706055; alpha 0.28242953648100017; mu 0\n",
      "Step 150; train loss 0.09010232985019684; train accuracy 98.4375; test loss 0.10768601298332214; test accuracy 97.02000021934509; alpha 0.28242953648100017; mu 0\n",
      "Step 200; train loss 0.14615289866924286; train accuracy 96.875; test loss 0.10785133391618729; test accuracy 97.07000255584717; alpha 0.28242953648100017; mu 0\n",
      "Step 250; train loss 0.06001046299934387; train accuracy 97.65625; test loss 0.10678636282682419; test accuracy 97.03999757766724; alpha 0.28242953648100017; mu 0\n",
      "Step 300; train loss 0.06905815005302429; train accuracy 99.21875; test loss 0.10582803934812546; test accuracy 97.13000059127808; alpha 0.28242953648100017; mu 0\n",
      "Step 350; train loss 0.14388670027256012; train accuracy 95.3125; test loss 0.10517939180135727; test accuracy 97.079998254776; alpha 0.28242953648100017; mu 0\n",
      "Step 400; train loss 0.06419450789690018; train accuracy 97.65625; test loss 0.10402540117502213; test accuracy 97.14999794960022; alpha 0.28242953648100017; mu 0\n",
      "EPOCH  13  : ##########\n",
      "Step 0; train loss 0.13407596945762634; train accuracy 96.875; test loss 0.10420653969049454; test accuracy 97.079998254776; alpha 0.25418658283290013; mu 0\n",
      "Step 50; train loss 0.05478304252028465; train accuracy 99.21875; test loss 0.10343945026397705; test accuracy 97.17000126838684; alpha 0.25418658283290013; mu 0\n",
      "Step 100; train loss 0.10455130785703659; train accuracy 97.65625; test loss 0.10343625396490097; test accuracy 97.15999960899353; alpha 0.25418658283290013; mu 0\n",
      "Step 150; train loss 0.06163790822029114; train accuracy 98.4375; test loss 0.1021164208650589; test accuracy 97.26999998092651; alpha 0.25418658283290013; mu 0\n",
      "Step 200; train loss 0.05205891281366348; train accuracy 99.21875; test loss 0.10243143141269684; test accuracy 97.2100019454956; alpha 0.25418658283290013; mu 0\n",
      "Step 250; train loss 0.08827425539493561; train accuracy 99.21875; test loss 0.10037539154291153; test accuracy 97.32999801635742; alpha 0.25418658283290013; mu 0\n",
      "Step 300; train loss 0.08837896585464478; train accuracy 97.65625; test loss 0.10017140209674835; test accuracy 97.21999764442444; alpha 0.25418658283290013; mu 0\n",
      "Step 350; train loss 0.07812266796827316; train accuracy 97.65625; test loss 0.09943041950464249; test accuracy 97.33999967575073; alpha 0.25418658283290013; mu 0\n",
      "Step 400; train loss 0.08915182948112488; train accuracy 97.65625; test loss 0.09912953525781631; test accuracy 97.24000096321106; alpha 0.25418658283290013; mu 0\n",
      "EPOCH  14  : ##########\n",
      "Step 0; train loss 0.11151348054409027; train accuracy 96.09375; test loss 0.09848210960626602; test accuracy 97.2100019454956; alpha 0.22876792454961012; mu 0\n",
      "Step 50; train loss 0.1004939079284668; train accuracy 96.875; test loss 0.09822198748588562; test accuracy 97.2599983215332; alpha 0.22876792454961012; mu 0\n",
      "Step 100; train loss 0.04555106163024902; train accuracy 99.21875; test loss 0.09857715666294098; test accuracy 97.24000096321106; alpha 0.22876792454961012; mu 0\n",
      "Step 150; train loss 0.0843629390001297; train accuracy 96.875; test loss 0.09742956608533859; test accuracy 97.26999998092651; alpha 0.22876792454961012; mu 0\n",
      "Step 200; train loss 0.09561698138713837; train accuracy 96.09375; test loss 0.09709328413009644; test accuracy 97.2599983215332; alpha 0.22876792454961012; mu 0\n",
      "Step 250; train loss 0.06809436529874802; train accuracy 99.21875; test loss 0.09688485413789749; test accuracy 97.31000065803528; alpha 0.22876792454961012; mu 0\n",
      "Step 300; train loss 0.099022775888443; train accuracy 97.65625; test loss 0.09534133225679398; test accuracy 97.35000133514404; alpha 0.22876792454961012; mu 0\n",
      "Step 350; train loss 0.060629021376371384; train accuracy 98.4375; test loss 0.09500208497047424; test accuracy 97.39000201225281; alpha 0.22876792454961012; mu 0\n",
      "Step 400; train loss 0.0318954661488533; train accuracy 100.0; test loss 0.09440924227237701; test accuracy 97.33999967575073; alpha 0.22876792454961012; mu 0\n",
      "EPOCH  15  : ##########\n",
      "Step 0; train loss 0.03979117423295975; train accuracy 100.0; test loss 0.09466972947120667; test accuracy 97.35999703407288; alpha 0.2058911320946491; mu 0\n",
      "Step 50; train loss 0.06260126829147339; train accuracy 98.4375; test loss 0.09441414475440979; test accuracy 97.40999937057495; alpha 0.2058911320946491; mu 0\n",
      "Step 100; train loss 0.06253919750452042; train accuracy 97.65625; test loss 0.09351664036512375; test accuracy 97.35999703407288; alpha 0.2058911320946491; mu 0\n",
      "Step 150; train loss 0.045553021132946014; train accuracy 99.21875; test loss 0.09355340898036957; test accuracy 97.35999703407288; alpha 0.2058911320946491; mu 0\n",
      "Step 200; train loss 0.060965266078710556; train accuracy 98.4375; test loss 0.0934164822101593; test accuracy 97.42000102996826; alpha 0.2058911320946491; mu 0\n",
      "Step 250; train loss 0.07272428274154663; train accuracy 97.65625; test loss 0.09225030988454819; test accuracy 97.46999740600586; alpha 0.2058911320946491; mu 0\n",
      "Step 300; train loss 0.04855909198522568; train accuracy 99.21875; test loss 0.0916723906993866; test accuracy 97.49000072479248; alpha 0.2058911320946491; mu 0\n",
      "Step 350; train loss 0.16326060891151428; train accuracy 94.53125; test loss 0.09138235449790955; test accuracy 97.42000102996826; alpha 0.2058911320946491; mu 0\n",
      "Step 400; train loss 0.056668251752853394; train accuracy 98.4375; test loss 0.09089288115501404; test accuracy 97.39000201225281; alpha 0.2058911320946491; mu 0\n",
      "EPOCH  16  : ##########\n",
      "Step 0; train loss 0.09345075488090515; train accuracy 97.65625; test loss 0.09062313288450241; test accuracy 97.40999937057495; alpha 0.1853020188851842; mu 0\n",
      "Step 50; train loss 0.053786225616931915; train accuracy 98.4375; test loss 0.09152324497699738; test accuracy 97.43000268936157; alpha 0.1853020188851842; mu 0\n",
      "Step 100; train loss 0.043533701449632645; train accuracy 99.21875; test loss 0.09115327149629593; test accuracy 97.3800003528595; alpha 0.1853020188851842; mu 0\n",
      "Step 150; train loss 0.03913593292236328; train accuracy 99.21875; test loss 0.08958008140325546; test accuracy 97.46000170707703; alpha 0.1853020188851842; mu 0\n",
      "Step 200; train loss 0.14971451461315155; train accuracy 96.09375; test loss 0.08932504802942276; test accuracy 97.45000004768372; alpha 0.1853020188851842; mu 0\n",
      "Step 250; train loss 0.09827448427677155; train accuracy 98.4375; test loss 0.08894889801740646; test accuracy 97.40999937057495; alpha 0.1853020188851842; mu 0\n",
      "Step 300; train loss 0.09157297015190125; train accuracy 96.09375; test loss 0.08790461719036102; test accuracy 97.49000072479248; alpha 0.1853020188851842; mu 0\n",
      "Step 350; train loss 0.052466847002506256; train accuracy 99.21875; test loss 0.0879461020231247; test accuracy 97.46000170707703; alpha 0.1853020188851842; mu 0\n",
      "Step 400; train loss 0.08338184654712677; train accuracy 96.875; test loss 0.08821961283683777; test accuracy 97.40999937057495; alpha 0.1853020188851842; mu 0\n",
      "EPOCH  17  : ##########\n",
      "Step 0; train loss 0.04714496433734894; train accuracy 99.21875; test loss 0.08778925240039825; test accuracy 97.43000268936157; alpha 0.16677181699666577; mu 0\n",
      "Step 50; train loss 0.05298980697989464; train accuracy 100.0; test loss 0.08766882121562958; test accuracy 97.45000004768372; alpha 0.16677181699666577; mu 0\n",
      "Step 100; train loss 0.02591722272336483; train accuracy 100.0; test loss 0.08739444613456726; test accuracy 97.49000072479248; alpha 0.16677181699666577; mu 0\n",
      "Step 150; train loss 0.06470188498497009; train accuracy 98.4375; test loss 0.08610732108354568; test accuracy 97.50999808311462; alpha 0.16677181699666577; mu 0\n",
      "Step 200; train loss 0.038605645298957825; train accuracy 99.21875; test loss 0.08681059628725052; test accuracy 97.50999808311462; alpha 0.16677181699666577; mu 0\n",
      "Step 250; train loss 0.051400184631347656; train accuracy 99.21875; test loss 0.08787578344345093; test accuracy 97.40999937057495; alpha 0.16677181699666577; mu 0\n",
      "Step 300; train loss 0.0662045031785965; train accuracy 98.4375; test loss 0.08635443449020386; test accuracy 97.50999808311462; alpha 0.16677181699666577; mu 0\n",
      "Step 350; train loss 0.08205367624759674; train accuracy 97.65625; test loss 0.08601614087820053; test accuracy 97.45000004768372; alpha 0.16677181699666577; mu 0\n",
      "Step 400; train loss 0.05400915443897247; train accuracy 99.21875; test loss 0.08623261004686356; test accuracy 97.46999740600586; alpha 0.16677181699666577; mu 0\n",
      "EPOCH  18  : ##########\n",
      "Step 0; train loss 0.041336268186569214; train accuracy 99.21875; test loss 0.08522863686084747; test accuracy 97.5600004196167; alpha 0.1500946352969992; mu 0\n",
      "Step 50; train loss 0.07757288962602615; train accuracy 98.4375; test loss 0.08555710315704346; test accuracy 97.61999845504761; alpha 0.1500946352969992; mu 0\n",
      "Step 100; train loss 0.07920324802398682; train accuracy 98.4375; test loss 0.08468315750360489; test accuracy 97.47999906539917; alpha 0.1500946352969992; mu 0\n",
      "Step 150; train loss 0.03310956805944443; train accuracy 99.21875; test loss 0.08377117663621902; test accuracy 97.53999710083008; alpha 0.1500946352969992; mu 0\n",
      "Step 200; train loss 0.050357360392808914; train accuracy 98.4375; test loss 0.08410230278968811; test accuracy 97.53999710083008; alpha 0.1500946352969992; mu 0\n",
      "Step 250; train loss 0.018596665933728218; train accuracy 100.0; test loss 0.08360789716243744; test accuracy 97.53999710083008; alpha 0.1500946352969992; mu 0\n",
      "Step 300; train loss 0.09169110655784607; train accuracy 97.65625; test loss 0.08425122499465942; test accuracy 97.53000140190125; alpha 0.1500946352969992; mu 0\n",
      "Step 350; train loss 0.05873613432049751; train accuracy 97.65625; test loss 0.08305175602436066; test accuracy 97.53000140190125; alpha 0.1500946352969992; mu 0\n",
      "Step 400; train loss 0.023045385256409645; train accuracy 100.0; test loss 0.08337690681219101; test accuracy 97.49000072479248; alpha 0.1500946352969992; mu 0\n",
      "EPOCH  19  : ##########\n",
      "Step 0; train loss 0.03698364272713661; train accuracy 100.0; test loss 0.08391431719064713; test accuracy 97.53999710083008; alpha 0.13508517176729928; mu 0\n",
      "Step 50; train loss 0.059275392442941666; train accuracy 98.4375; test loss 0.08334296196699142; test accuracy 97.49000072479248; alpha 0.13508517176729928; mu 0\n",
      "Step 100; train loss 0.07362978160381317; train accuracy 96.875; test loss 0.08297660201787949; test accuracy 97.50000238418579; alpha 0.13508517176729928; mu 0\n",
      "Step 150; train loss 0.03690733388066292; train accuracy 100.0; test loss 0.08375830203294754; test accuracy 97.58999943733215; alpha 0.13508517176729928; mu 0\n",
      "Step 200; train loss 0.03263002634048462; train accuracy 99.21875; test loss 0.08283885568380356; test accuracy 97.67000079154968; alpha 0.13508517176729928; mu 0\n",
      "Step 250; train loss 0.03214835748076439; train accuracy 100.0; test loss 0.08253876119852066; test accuracy 97.61999845504761; alpha 0.13508517176729928; mu 0\n",
      "Step 300; train loss 0.05079048126935959; train accuracy 99.21875; test loss 0.08326445519924164; test accuracy 97.53000140190125; alpha 0.13508517176729928; mu 0\n",
      "Step 350; train loss 0.03530818596482277; train accuracy 99.21875; test loss 0.08215179294347763; test accuracy 97.61000275611877; alpha 0.13508517176729928; mu 0\n",
      "Step 400; train loss 0.07593829929828644; train accuracy 97.65625; test loss 0.08145452290773392; test accuracy 97.5600004196167; alpha 0.13508517176729928; mu 0\n",
      "EPOCH  20  : ##########\n",
      "Step 0; train loss 0.1043134555220604; train accuracy 97.65625; test loss 0.08200597018003464; test accuracy 97.60000109672546; alpha 0.12157665459056936; mu 0\n",
      "Step 50; train loss 0.03969648480415344; train accuracy 98.4375; test loss 0.08260153979063034; test accuracy 97.53000140190125; alpha 0.12157665459056936; mu 0\n",
      "Step 100; train loss 0.04974434897303581; train accuracy 97.65625; test loss 0.08195307105779648; test accuracy 97.63000011444092; alpha 0.12157665459056936; mu 0\n",
      "Step 150; train loss 0.05410231649875641; train accuracy 99.21875; test loss 0.08125291764736176; test accuracy 97.61000275611877; alpha 0.12157665459056936; mu 0\n",
      "Step 200; train loss 0.046740490943193436; train accuracy 98.4375; test loss 0.08009851723909378; test accuracy 97.53000140190125; alpha 0.12157665459056936; mu 0\n",
      "Step 250; train loss 0.07588024437427521; train accuracy 96.875; test loss 0.0794479250907898; test accuracy 97.53000140190125; alpha 0.12157665459056936; mu 0\n",
      "Step 300; train loss 0.02198031172156334; train accuracy 100.0; test loss 0.08073972910642624; test accuracy 97.61000275611877; alpha 0.12157665459056936; mu 0\n",
      "Step 350; train loss 0.07009930908679962; train accuracy 97.65625; test loss 0.07931720465421677; test accuracy 97.63000011444092; alpha 0.12157665459056936; mu 0\n",
      "Step 400; train loss 0.056079186499118805; train accuracy 97.65625; test loss 0.0795411542057991; test accuracy 97.61999845504761; alpha 0.12157665459056936; mu 0\n",
      "EPOCH  21  : ##########\n",
      "Step 0; train loss 0.03982528671622276; train accuracy 98.4375; test loss 0.07994246482849121; test accuracy 97.64999747276306; alpha 0.10941898913151243; mu 0\n",
      "Step 50; train loss 0.028108172118663788; train accuracy 100.0; test loss 0.07909701019525528; test accuracy 97.69999980926514; alpha 0.10941898913151243; mu 0\n",
      "Step 100; train loss 0.031161027029156685; train accuracy 100.0; test loss 0.07848270237445831; test accuracy 97.68999814987183; alpha 0.10941898913151243; mu 0\n",
      "Step 150; train loss 0.09732823818922043; train accuracy 96.875; test loss 0.07928629219532013; test accuracy 97.61999845504761; alpha 0.10941898913151243; mu 0\n",
      "Step 200; train loss 0.0321122370660305; train accuracy 99.21875; test loss 0.07977036386728287; test accuracy 97.63000011444092; alpha 0.10941898913151243; mu 0\n",
      "Step 250; train loss 0.040811531245708466; train accuracy 98.4375; test loss 0.07825110107660294; test accuracy 97.69999980926514; alpha 0.10941898913151243; mu 0\n",
      "Step 300; train loss 0.04106525704264641; train accuracy 98.4375; test loss 0.07749668508768082; test accuracy 97.64000177383423; alpha 0.10941898913151243; mu 0\n",
      "Step 350; train loss 0.044209614396095276; train accuracy 99.21875; test loss 0.07790473103523254; test accuracy 97.61000275611877; alpha 0.10941898913151243; mu 0\n",
      "Step 400; train loss 0.0416664183139801; train accuracy 99.21875; test loss 0.07834137976169586; test accuracy 97.53999710083008; alpha 0.10941898913151243; mu 0\n",
      "EPOCH  22  : ##########\n",
      "Step 0; train loss 0.023492414504289627; train accuracy 100.0; test loss 0.07880326360464096; test accuracy 97.60000109672546; alpha 0.0984770902183612; mu 0\n",
      "Step 50; train loss 0.05208177492022514; train accuracy 99.21875; test loss 0.07885809987783432; test accuracy 97.53999710083008; alpha 0.0984770902183612; mu 0\n",
      "Step 100; train loss 0.07535374164581299; train accuracy 96.09375; test loss 0.07923188805580139; test accuracy 97.51999974250793; alpha 0.0984770902183612; mu 0\n",
      "Step 150; train loss 0.08124873042106628; train accuracy 97.65625; test loss 0.07811404764652252; test accuracy 97.63000011444092; alpha 0.0984770902183612; mu 0\n",
      "Step 200; train loss 0.044890642166137695; train accuracy 98.4375; test loss 0.07731185853481293; test accuracy 97.69999980926514; alpha 0.0984770902183612; mu 0\n",
      "Step 250; train loss 0.03686964139342308; train accuracy 98.4375; test loss 0.0776078850030899; test accuracy 97.5600004196167; alpha 0.0984770902183612; mu 0\n",
      "Step 300; train loss 0.02840258553624153; train accuracy 99.21875; test loss 0.07702485471963882; test accuracy 97.63000011444092; alpha 0.0984770902183612; mu 0\n",
      "Step 350; train loss 0.03448546677827835; train accuracy 99.21875; test loss 0.07708945870399475; test accuracy 97.71999716758728; alpha 0.0984770902183612; mu 0\n",
      "Step 400; train loss 0.0633244663476944; train accuracy 98.4375; test loss 0.07774010300636292; test accuracy 97.67000079154968; alpha 0.0984770902183612; mu 0\n",
      "EPOCH  23  : ##########\n",
      "Step 0; train loss 0.021645504981279373; train accuracy 100.0; test loss 0.07752028852701187; test accuracy 97.61999845504761; alpha 0.08862938119652508; mu 0\n",
      "Step 50; train loss 0.08863063156604767; train accuracy 97.65625; test loss 0.0770457312464714; test accuracy 97.63000011444092; alpha 0.08862938119652508; mu 0\n",
      "Step 100; train loss 0.014009540900588036; train accuracy 100.0; test loss 0.07646418362855911; test accuracy 97.67000079154968; alpha 0.08862938119652508; mu 0\n",
      "Step 150; train loss 0.0247911736369133; train accuracy 100.0; test loss 0.07701801508665085; test accuracy 97.64000177383423; alpha 0.08862938119652508; mu 0\n",
      "Step 200; train loss 0.06729350984096527; train accuracy 98.4375; test loss 0.07655676454305649; test accuracy 97.65999913215637; alpha 0.08862938119652508; mu 0\n",
      "Step 250; train loss 0.05486510694026947; train accuracy 99.21875; test loss 0.07528197765350342; test accuracy 97.69999980926514; alpha 0.08862938119652508; mu 0\n",
      "Step 300; train loss 0.030232692137360573; train accuracy 99.21875; test loss 0.07559338212013245; test accuracy 97.680002450943; alpha 0.08862938119652508; mu 0\n",
      "Step 350; train loss 0.03418489545583725; train accuracy 100.0; test loss 0.074777752161026; test accuracy 97.78000116348267; alpha 0.08862938119652508; mu 0\n",
      "Step 400; train loss 0.040374673902988434; train accuracy 99.21875; test loss 0.07518307864665985; test accuracy 97.71999716758728; alpha 0.08862938119652508; mu 0\n",
      "EPOCH  24  : ##########\n",
      "Step 0; train loss 0.02494167536497116; train accuracy 100.0; test loss 0.07522539049386978; test accuracy 97.75999784469604; alpha 0.07976644307687257; mu 0\n",
      "Step 50; train loss 0.019452430307865143; train accuracy 100.0; test loss 0.07468996942043304; test accuracy 97.68999814987183; alpha 0.07976644307687257; mu 0\n",
      "Step 100; train loss 0.043460287153720856; train accuracy 99.21875; test loss 0.07493504881858826; test accuracy 97.75999784469604; alpha 0.07976644307687257; mu 0\n",
      "Step 150; train loss 0.02520596608519554; train accuracy 99.21875; test loss 0.07557640224695206; test accuracy 97.7400004863739; alpha 0.07976644307687257; mu 0\n",
      "Step 200; train loss 0.05932924896478653; train accuracy 97.65625; test loss 0.07654915004968643; test accuracy 97.67000079154968; alpha 0.07976644307687257; mu 0\n",
      "Step 250; train loss 0.050915446132421494; train accuracy 96.875; test loss 0.0762786865234375; test accuracy 97.64999747276306; alpha 0.07976644307687257; mu 0\n",
      "Step 300; train loss 0.04055240377783775; train accuracy 98.4375; test loss 0.07674328982830048; test accuracy 97.61999845504761; alpha 0.07976644307687257; mu 0\n",
      "Step 350; train loss 0.07103455066680908; train accuracy 99.21875; test loss 0.07592922449111938; test accuracy 97.71000146865845; alpha 0.07976644307687257; mu 0\n",
      "Step 400; train loss 0.022921942174434662; train accuracy 100.0; test loss 0.07512325793504715; test accuracy 97.68999814987183; alpha 0.07976644307687257; mu 0\n",
      "EPOCH  25  : ##########\n",
      "Step 0; train loss 0.02738710306584835; train accuracy 100.0; test loss 0.07522964477539062; test accuracy 97.78000116348267; alpha 0.07178979876918531; mu 0\n",
      "Step 50; train loss 0.06008218973875046; train accuracy 97.65625; test loss 0.07525601238012314; test accuracy 97.75000214576721; alpha 0.07178979876918531; mu 0\n",
      "Step 100; train loss 0.03137142211198807; train accuracy 99.21875; test loss 0.07507220655679703; test accuracy 97.71999716758728; alpha 0.07178979876918531; mu 0\n",
      "Step 150; train loss 0.037701163440942764; train accuracy 99.21875; test loss 0.07559274882078171; test accuracy 97.67000079154968; alpha 0.07178979876918531; mu 0\n",
      "Step 200; train loss 0.043264053761959076; train accuracy 99.21875; test loss 0.07593458890914917; test accuracy 97.67000079154968; alpha 0.07178979876918531; mu 0\n",
      "Step 250; train loss 0.023613499477505684; train accuracy 100.0; test loss 0.07574652135372162; test accuracy 97.75000214576721; alpha 0.07178979876918531; mu 0\n",
      "Step 300; train loss 0.02740977145731449; train accuracy 99.21875; test loss 0.0753922164440155; test accuracy 97.680002450943; alpha 0.07178979876918531; mu 0\n",
      "Step 350; train loss 0.03719446435570717; train accuracy 99.21875; test loss 0.07451283931732178; test accuracy 97.75000214576721; alpha 0.07178979876918531; mu 0\n",
      "Step 400; train loss 0.03839784488081932; train accuracy 99.21875; test loss 0.07413385063409805; test accuracy 97.67000079154968; alpha 0.07178979876918531; mu 0\n",
      "EPOCH  26  : ##########\n",
      "Step 0; train loss 0.036910947412252426; train accuracy 100.0; test loss 0.07393663376569748; test accuracy 97.680002450943; alpha 0.06461081889226679; mu 0\n",
      "Step 50; train loss 0.027135197073221207; train accuracy 100.0; test loss 0.07367333024740219; test accuracy 97.67000079154968; alpha 0.06461081889226679; mu 0\n",
      "Step 100; train loss 0.0449901781976223; train accuracy 99.21875; test loss 0.07284293323755264; test accuracy 97.7400004863739; alpha 0.06461081889226679; mu 0\n",
      "Step 150; train loss 0.021923065185546875; train accuracy 100.0; test loss 0.07362312078475952; test accuracy 97.71000146865845; alpha 0.06461081889226679; mu 0\n",
      "Step 200; train loss 0.016324473544955254; train accuracy 100.0; test loss 0.07420694828033447; test accuracy 97.71999716758728; alpha 0.06461081889226679; mu 0\n",
      "Step 250; train loss 0.03371446579694748; train accuracy 98.4375; test loss 0.07420766353607178; test accuracy 97.75000214576721; alpha 0.06461081889226679; mu 0\n",
      "Step 300; train loss 0.031008921563625336; train accuracy 99.21875; test loss 0.07517752051353455; test accuracy 97.68999814987183; alpha 0.06461081889226679; mu 0\n",
      "Step 350; train loss 0.034494563937187195; train accuracy 99.21875; test loss 0.0737343356013298; test accuracy 97.82999753952026; alpha 0.06461081889226679; mu 0\n",
      "Step 400; train loss 0.026235060766339302; train accuracy 100.0; test loss 0.07453004270792007; test accuracy 97.69999980926514; alpha 0.06461081889226679; mu 0\n",
      "EPOCH  27  : ##########\n",
      "Step 0; train loss 0.030601592734456062; train accuracy 98.4375; test loss 0.07426027208566666; test accuracy 97.7400004863739; alpha 0.05814973700304011; mu 0\n",
      "Step 50; train loss 0.036769263446331024; train accuracy 99.21875; test loss 0.07366567850112915; test accuracy 97.71000146865845; alpha 0.05814973700304011; mu 0\n",
      "Step 100; train loss 0.013691391795873642; train accuracy 100.0; test loss 0.07399856299161911; test accuracy 97.71999716758728; alpha 0.05814973700304011; mu 0\n",
      "Step 150; train loss 0.012212790548801422; train accuracy 100.0; test loss 0.07380913943052292; test accuracy 97.79000282287598; alpha 0.05814973700304011; mu 0\n",
      "Step 200; train loss 0.03318661451339722; train accuracy 99.21875; test loss 0.07377170771360397; test accuracy 97.78000116348267; alpha 0.05814973700304011; mu 0\n",
      "Step 250; train loss 0.0255889929831028; train accuracy 100.0; test loss 0.07403054088354111; test accuracy 97.76999950408936; alpha 0.05814973700304011; mu 0\n",
      "Step 300; train loss 0.03870401531457901; train accuracy 98.4375; test loss 0.07414562255144119; test accuracy 97.75000214576721; alpha 0.05814973700304011; mu 0\n",
      "Step 350; train loss 0.016497410833835602; train accuracy 99.21875; test loss 0.07404676824808121; test accuracy 97.68999814987183; alpha 0.05814973700304011; mu 0\n",
      "Step 400; train loss 0.03430457413196564; train accuracy 100.0; test loss 0.07470890879631042; test accuracy 97.72999882698059; alpha 0.05814973700304011; mu 0\n",
      "EPOCH  28  : ##########\n",
      "Step 0; train loss 0.02415907196700573; train accuracy 100.0; test loss 0.07312355935573578; test accuracy 97.71000146865845; alpha 0.0523347633027361; mu 0\n",
      "Step 50; train loss 0.030122414231300354; train accuracy 99.21875; test loss 0.07287656515836716; test accuracy 97.81000018119812; alpha 0.0523347633027361; mu 0\n",
      "Step 100; train loss 0.017616145312786102; train accuracy 100.0; test loss 0.0728292390704155; test accuracy 97.79000282287598; alpha 0.0523347633027361; mu 0\n",
      "Step 150; train loss 0.048478271812200546; train accuracy 98.4375; test loss 0.07403241097927094; test accuracy 97.69999980926514; alpha 0.0523347633027361; mu 0\n",
      "Step 200; train loss 0.019699502736330032; train accuracy 100.0; test loss 0.07413439452648163; test accuracy 97.75000214576721; alpha 0.0523347633027361; mu 0\n",
      "Step 250; train loss 0.007216844707727432; train accuracy 100.0; test loss 0.07362987846136093; test accuracy 97.76999950408936; alpha 0.0523347633027361; mu 0\n",
      "Step 300; train loss 0.02607337385416031; train accuracy 99.21875; test loss 0.07347933202981949; test accuracy 97.78000116348267; alpha 0.0523347633027361; mu 0\n",
      "Step 350; train loss 0.010005123913288116; train accuracy 100.0; test loss 0.07312668859958649; test accuracy 97.75999784469604; alpha 0.0523347633027361; mu 0\n",
      "Step 400; train loss 0.025043368339538574; train accuracy 100.0; test loss 0.07251081615686417; test accuracy 97.79000282287598; alpha 0.0523347633027361; mu 0\n",
      "EPOCH  29  : ##########\n",
      "Step 0; train loss 0.01845778524875641; train accuracy 100.0; test loss 0.07296359539031982; test accuracy 97.72999882698059; alpha 0.04710128697246249; mu 0\n",
      "Step 50; train loss 0.021891437470912933; train accuracy 100.0; test loss 0.07223108410835266; test accuracy 97.69999980926514; alpha 0.04710128697246249; mu 0\n",
      "Step 100; train loss 0.03788589686155319; train accuracy 99.21875; test loss 0.07206238061189651; test accuracy 97.82999753952026; alpha 0.04710128697246249; mu 0\n",
      "Step 150; train loss 0.06526147574186325; train accuracy 99.21875; test loss 0.07273037731647491; test accuracy 97.75999784469604; alpha 0.04710128697246249; mu 0\n",
      "Step 200; train loss 0.02119160257279873; train accuracy 100.0; test loss 0.07296426594257355; test accuracy 97.71000146865845; alpha 0.04710128697246249; mu 0\n",
      "Step 250; train loss 0.01846327818930149; train accuracy 100.0; test loss 0.07286188751459122; test accuracy 97.75999784469604; alpha 0.04710128697246249; mu 0\n",
      "Step 300; train loss 0.021620970219373703; train accuracy 100.0; test loss 0.07323329895734787; test accuracy 97.75999784469604; alpha 0.04710128697246249; mu 0\n",
      "Step 350; train loss 0.023449547588825226; train accuracy 100.0; test loss 0.07310151308774948; test accuracy 97.67000079154968; alpha 0.04710128697246249; mu 0\n",
      "Step 400; train loss 0.018727073445916176; train accuracy 100.0; test loss 0.07329972088336945; test accuracy 97.78000116348267; alpha 0.04710128697246249; mu 0\n",
      "EPOCH  30  : ##########\n",
      "Step 0; train loss 0.013925185427069664; train accuracy 100.0; test loss 0.07221528142690659; test accuracy 97.76999950408936; alpha 0.042391158275216244; mu 0\n",
      "Step 50; train loss 0.04254165291786194; train accuracy 98.4375; test loss 0.07263647764921188; test accuracy 97.75999784469604; alpha 0.042391158275216244; mu 0\n",
      "Step 100; train loss 0.022297155112028122; train accuracy 100.0; test loss 0.0729471743106842; test accuracy 97.7400004863739; alpha 0.042391158275216244; mu 0\n",
      "Step 150; train loss 0.015506705269217491; train accuracy 100.0; test loss 0.07213043421506882; test accuracy 97.79999852180481; alpha 0.042391158275216244; mu 0\n",
      "Step 200; train loss 0.031899288296699524; train accuracy 99.21875; test loss 0.0721399188041687; test accuracy 97.82999753952026; alpha 0.042391158275216244; mu 0\n",
      "Step 250; train loss 0.02686222642660141; train accuracy 99.21875; test loss 0.07220380008220673; test accuracy 97.76999950408936; alpha 0.042391158275216244; mu 0\n",
      "Step 300; train loss 0.021487727761268616; train accuracy 100.0; test loss 0.07309328019618988; test accuracy 97.85000085830688; alpha 0.042391158275216244; mu 0\n",
      "Step 350; train loss 0.03458821028470993; train accuracy 99.21875; test loss 0.07167316973209381; test accuracy 97.81000018119812; alpha 0.042391158275216244; mu 0\n",
      "Step 400; train loss 0.03712354227900505; train accuracy 99.21875; test loss 0.07359497249126434; test accuracy 97.71999716758728; alpha 0.042391158275216244; mu 0\n",
      "EPOCH  31  : ##########\n",
      "Step 0; train loss 0.01651446521282196; train accuracy 100.0; test loss 0.07359426468610764; test accuracy 97.68999814987183; alpha 0.03815204244769462; mu 0\n",
      "Step 50; train loss 0.03238038718700409; train accuracy 99.21875; test loss 0.07218260318040848; test accuracy 97.8600025177002; alpha 0.03815204244769462; mu 0\n",
      "Step 100; train loss 0.01804329641163349; train accuracy 100.0; test loss 0.07219696044921875; test accuracy 97.82000184059143; alpha 0.03815204244769462; mu 0\n",
      "Step 150; train loss 0.012792455963790417; train accuracy 100.0; test loss 0.07198230922222137; test accuracy 97.81000018119812; alpha 0.03815204244769462; mu 0\n",
      "Step 200; train loss 0.010045785456895828; train accuracy 100.0; test loss 0.07197698950767517; test accuracy 97.86999821662903; alpha 0.03815204244769462; mu 0\n",
      "Step 250; train loss 0.02351226657629013; train accuracy 100.0; test loss 0.07327186316251755; test accuracy 97.79000282287598; alpha 0.03815204244769462; mu 0\n",
      "Step 300; train loss 0.021936751902103424; train accuracy 100.0; test loss 0.07127290219068527; test accuracy 97.83999919891357; alpha 0.03815204244769462; mu 0\n",
      "Step 350; train loss 0.028045807033777237; train accuracy 99.21875; test loss 0.07210876792669296; test accuracy 97.79000282287598; alpha 0.03815204244769462; mu 0\n",
      "Step 400; train loss 0.04756387323141098; train accuracy 99.21875; test loss 0.07223418354988098; test accuracy 97.79000282287598; alpha 0.03815204244769462; mu 0\n",
      "EPOCH  32  : ##########\n",
      "Step 0; train loss 0.02471962198615074; train accuracy 100.0; test loss 0.0727003887295723; test accuracy 97.71999716758728; alpha 0.03433683820292516; mu 0\n",
      "Step 50; train loss 0.013722684234380722; train accuracy 100.0; test loss 0.07271962612867355; test accuracy 97.75000214576721; alpha 0.03433683820292516; mu 0\n",
      "Step 100; train loss 0.016991330310702324; train accuracy 100.0; test loss 0.07262106984853745; test accuracy 97.79000282287598; alpha 0.03433683820292516; mu 0\n",
      "Step 150; train loss 0.010346131399273872; train accuracy 100.0; test loss 0.07186389714479446; test accuracy 97.81000018119812; alpha 0.03433683820292516; mu 0\n",
      "Step 200; train loss 0.04324447736144066; train accuracy 99.21875; test loss 0.07208088040351868; test accuracy 97.79999852180481; alpha 0.03433683820292516; mu 0\n",
      "Step 250; train loss 0.02146259695291519; train accuracy 99.21875; test loss 0.07308948040008545; test accuracy 97.75999784469604; alpha 0.03433683820292516; mu 0\n",
      "Step 300; train loss 0.01792837306857109; train accuracy 100.0; test loss 0.07363878935575485; test accuracy 97.81000018119812; alpha 0.03433683820292516; mu 0\n",
      "Step 350; train loss 0.05893849954009056; train accuracy 97.65625; test loss 0.0730988010764122; test accuracy 97.82999753952026; alpha 0.03433683820292516; mu 0\n",
      "Step 400; train loss 0.03139837086200714; train accuracy 99.21875; test loss 0.07088056206703186; test accuracy 97.78000116348267; alpha 0.03433683820292516; mu 0\n",
      "EPOCH  33  : ##########\n",
      "Step 0; train loss 0.019640015438199043; train accuracy 100.0; test loss 0.07071918249130249; test accuracy 97.85000085830688; alpha 0.030903154382632643; mu 0\n",
      "Step 50; train loss 0.02107575535774231; train accuracy 100.0; test loss 0.07109038531780243; test accuracy 97.82999753952026; alpha 0.030903154382632643; mu 0\n",
      "Step 100; train loss 0.014621376059949398; train accuracy 100.0; test loss 0.07214087247848511; test accuracy 97.81000018119812; alpha 0.030903154382632643; mu 0\n",
      "Step 150; train loss 0.013457545079290867; train accuracy 100.0; test loss 0.07302307337522507; test accuracy 97.79000282287598; alpha 0.030903154382632643; mu 0\n",
      "Step 200; train loss 0.03473276644945145; train accuracy 99.21875; test loss 0.07216246426105499; test accuracy 97.86999821662903; alpha 0.030903154382632643; mu 0\n",
      "Step 250; train loss 0.018528718501329422; train accuracy 100.0; test loss 0.07235908508300781; test accuracy 97.82999753952026; alpha 0.030903154382632643; mu 0\n",
      "Step 300; train loss 0.015376611612737179; train accuracy 99.21875; test loss 0.07229889184236526; test accuracy 97.87999987602234; alpha 0.030903154382632643; mu 0\n",
      "Step 350; train loss 0.008925452828407288; train accuracy 100.0; test loss 0.07190798223018646; test accuracy 97.81000018119812; alpha 0.030903154382632643; mu 0\n",
      "Step 400; train loss 0.019065380096435547; train accuracy 100.0; test loss 0.07184157520532608; test accuracy 97.86999821662903; alpha 0.030903154382632643; mu 0\n",
      "EPOCH  34  : ##########\n",
      "Step 0; train loss 0.016925811767578125; train accuracy 100.0; test loss 0.07212448865175247; test accuracy 97.79999852180481; alpha 0.02781283894436938; mu 0\n",
      "Step 50; train loss 0.021606137976050377; train accuracy 100.0; test loss 0.07117129862308502; test accuracy 97.78000116348267; alpha 0.02781283894436938; mu 0\n",
      "Step 100; train loss 0.0373624786734581; train accuracy 99.21875; test loss 0.07180142402648926; test accuracy 97.82999753952026; alpha 0.02781283894436938; mu 0\n",
      "Step 150; train loss 0.009767011739313602; train accuracy 100.0; test loss 0.0723697617650032; test accuracy 97.75000214576721; alpha 0.02781283894436938; mu 0\n",
      "Step 200; train loss 0.020760541781783104; train accuracy 99.21875; test loss 0.07244100421667099; test accuracy 97.79000282287598; alpha 0.02781283894436938; mu 0\n",
      "Step 250; train loss 0.019497893750667572; train accuracy 100.0; test loss 0.07270585745573044; test accuracy 97.76999950408936; alpha 0.02781283894436938; mu 0\n",
      "Step 300; train loss 0.006364555563777685; train accuracy 100.0; test loss 0.07366858422756195; test accuracy 97.76999950408936; alpha 0.02781283894436938; mu 0\n",
      "Step 350; train loss 0.038392290472984314; train accuracy 97.65625; test loss 0.0723227933049202; test accuracy 97.86999821662903; alpha 0.02781283894436938; mu 0\n",
      "Step 400; train loss 0.0323442779481411; train accuracy 98.4375; test loss 0.07292463630437851; test accuracy 97.82000184059143; alpha 0.02781283894436938; mu 0\n",
      "EPOCH  35  : ##########\n",
      "Step 0; train loss 0.014926617965102196; train accuracy 100.0; test loss 0.07209550589323044; test accuracy 97.86999821662903; alpha 0.025031555049932444; mu 0\n",
      "Step 50; train loss 0.015607491135597229; train accuracy 100.0; test loss 0.07143734395503998; test accuracy 97.83999919891357; alpha 0.025031555049932444; mu 0\n",
      "Step 100; train loss 0.017756910994648933; train accuracy 100.0; test loss 0.07146904617547989; test accuracy 97.81000018119812; alpha 0.025031555049932444; mu 0\n",
      "Step 150; train loss 0.012664591893553734; train accuracy 99.21875; test loss 0.07119961082935333; test accuracy 97.8600025177002; alpha 0.025031555049932444; mu 0\n",
      "Step 200; train loss 0.0188202615827322; train accuracy 99.21875; test loss 0.07081151753664017; test accuracy 97.9200005531311; alpha 0.025031555049932444; mu 0\n",
      "Step 250; train loss 0.020081009715795517; train accuracy 100.0; test loss 0.07169097661972046; test accuracy 97.83999919891357; alpha 0.025031555049932444; mu 0\n",
      "Step 300; train loss 0.019726669415831566; train accuracy 100.0; test loss 0.07215797901153564; test accuracy 97.76999950408936; alpha 0.025031555049932444; mu 0\n",
      "Step 350; train loss 0.027329031378030777; train accuracy 100.0; test loss 0.07301062345504761; test accuracy 97.79000282287598; alpha 0.025031555049932444; mu 0\n",
      "Step 400; train loss 0.009296199306845665; train accuracy 100.0; test loss 0.07364477962255478; test accuracy 97.75999784469604; alpha 0.025031555049932444; mu 0\n",
      "EPOCH  36  : ##########\n",
      "Step 0; train loss 0.007514422759413719; train accuracy 100.0; test loss 0.07290005683898926; test accuracy 97.79000282287598; alpha 0.0225283995449392; mu 0\n",
      "Step 50; train loss 0.020202888175845146; train accuracy 100.0; test loss 0.07376091182231903; test accuracy 97.7400004863739; alpha 0.0225283995449392; mu 0\n",
      "Step 100; train loss 0.009680122137069702; train accuracy 100.0; test loss 0.07369080930948257; test accuracy 97.82999753952026; alpha 0.0225283995449392; mu 0\n",
      "Step 150; train loss 0.011722121387720108; train accuracy 100.0; test loss 0.07316435128450394; test accuracy 97.79000282287598; alpha 0.0225283995449392; mu 0\n",
      "Step 200; train loss 0.009905075654387474; train accuracy 100.0; test loss 0.07239281386137009; test accuracy 97.82000184059143; alpha 0.0225283995449392; mu 0\n",
      "Step 250; train loss 0.04680849611759186; train accuracy 99.21875; test loss 0.07339628040790558; test accuracy 97.81000018119812; alpha 0.0225283995449392; mu 0\n",
      "Step 300; train loss 0.009457390755414963; train accuracy 100.0; test loss 0.07149888575077057; test accuracy 97.76999950408936; alpha 0.0225283995449392; mu 0\n",
      "Step 350; train loss 0.0094973836094141; train accuracy 100.0; test loss 0.07233560085296631; test accuracy 97.75000214576721; alpha 0.0225283995449392; mu 0\n",
      "Step 400; train loss 0.022343669086694717; train accuracy 99.21875; test loss 0.07220426201820374; test accuracy 97.8600025177002; alpha 0.0225283995449392; mu 0\n",
      "EPOCH  37  : ##########\n",
      "Step 0; train loss 0.01122034527361393; train accuracy 100.0; test loss 0.07233758270740509; test accuracy 97.72999882698059; alpha 0.020275559590445278; mu 0\n",
      "Step 50; train loss 0.020941490307450294; train accuracy 99.21875; test loss 0.07207658886909485; test accuracy 97.79999852180481; alpha 0.020275559590445278; mu 0\n",
      "Step 100; train loss 0.012806731276214123; train accuracy 100.0; test loss 0.07137157022953033; test accuracy 97.78000116348267; alpha 0.020275559590445278; mu 0\n",
      "Step 150; train loss 0.043814752250909805; train accuracy 98.4375; test loss 0.07163932919502258; test accuracy 97.78000116348267; alpha 0.020275559590445278; mu 0\n",
      "Step 200; train loss 0.009574244730174541; train accuracy 100.0; test loss 0.07258783280849457; test accuracy 97.85000085830688; alpha 0.020275559590445278; mu 0\n",
      "Step 250; train loss 0.017868157476186752; train accuracy 100.0; test loss 0.07238636165857315; test accuracy 97.76999950408936; alpha 0.020275559590445278; mu 0\n",
      "Step 300; train loss 0.012222189456224442; train accuracy 100.0; test loss 0.0730871856212616; test accuracy 97.67000079154968; alpha 0.020275559590445278; mu 0\n",
      "Step 350; train loss 0.009081990458071232; train accuracy 100.0; test loss 0.07312776893377304; test accuracy 97.78000116348267; alpha 0.020275559590445278; mu 0\n",
      "Step 400; train loss 0.007889389991760254; train accuracy 100.0; test loss 0.07244586199522018; test accuracy 97.71000146865845; alpha 0.020275559590445278; mu 0\n",
      "EPOCH  38  : ##########\n",
      "Step 0; train loss 0.015722133219242096; train accuracy 100.0; test loss 0.07188113033771515; test accuracy 97.72999882698059; alpha 0.01824800363140075; mu 0\n",
      "Step 50; train loss 0.018943827599287033; train accuracy 100.0; test loss 0.07188733667135239; test accuracy 97.71999716758728; alpha 0.01824800363140075; mu 0\n",
      "Step 100; train loss 0.00728562893345952; train accuracy 100.0; test loss 0.07165206968784332; test accuracy 97.81000018119812; alpha 0.01824800363140075; mu 0\n",
      "Step 150; train loss 0.022438425570726395; train accuracy 100.0; test loss 0.07246458530426025; test accuracy 97.75999784469604; alpha 0.01824800363140075; mu 0\n",
      "Step 200; train loss 0.03115902468562126; train accuracy 99.21875; test loss 0.07237054407596588; test accuracy 97.86999821662903; alpha 0.01824800363140075; mu 0\n",
      "Step 250; train loss 0.023578673601150513; train accuracy 99.21875; test loss 0.0719340369105339; test accuracy 97.89999723434448; alpha 0.01824800363140075; mu 0\n",
      "Step 300; train loss 0.03481489047408104; train accuracy 98.4375; test loss 0.0720968022942543; test accuracy 97.75000214576721; alpha 0.01824800363140075; mu 0\n",
      "Step 350; train loss 0.02255379408597946; train accuracy 100.0; test loss 0.07154671847820282; test accuracy 97.85000085830688; alpha 0.01824800363140075; mu 0\n",
      "Step 400; train loss 0.032982997596263885; train accuracy 99.21875; test loss 0.07161832600831985; test accuracy 97.8600025177002; alpha 0.01824800363140075; mu 0\n",
      "EPOCH  39  : ##########\n",
      "Step 0; train loss 0.03077884204685688; train accuracy 99.21875; test loss 0.07222346216440201; test accuracy 97.81000018119812; alpha 0.016423203268260675; mu 0\n",
      "Step 50; train loss 0.011123962700366974; train accuracy 100.0; test loss 0.0727372094988823; test accuracy 97.86999821662903; alpha 0.016423203268260675; mu 0\n",
      "Step 100; train loss 0.012046372517943382; train accuracy 100.0; test loss 0.07215376943349838; test accuracy 97.81000018119812; alpha 0.016423203268260675; mu 0\n",
      "Step 150; train loss 0.020574267953634262; train accuracy 99.21875; test loss 0.0718940943479538; test accuracy 97.82000184059143; alpha 0.016423203268260675; mu 0\n",
      "Step 200; train loss 0.008781378157436848; train accuracy 100.0; test loss 0.07119323313236237; test accuracy 97.82999753952026; alpha 0.016423203268260675; mu 0\n",
      "Step 250; train loss 0.025261130183935165; train accuracy 99.21875; test loss 0.07084301859140396; test accuracy 97.86999821662903; alpha 0.016423203268260675; mu 0\n",
      "Step 300; train loss 0.006224465556442738; train accuracy 100.0; test loss 0.07260177284479141; test accuracy 97.83999919891357; alpha 0.016423203268260675; mu 0\n",
      "Step 350; train loss 0.008680206723511219; train accuracy 100.0; test loss 0.07340211421251297; test accuracy 97.75999784469604; alpha 0.016423203268260675; mu 0\n",
      "Step 400; train loss 0.023225273936986923; train accuracy 99.21875; test loss 0.07161759585142136; test accuracy 97.71999716758728; alpha 0.016423203268260675; mu 0\n",
      "EPOCH  40  : ##########\n",
      "Step 0; train loss 0.006721452344208956; train accuracy 100.0; test loss 0.07126330584287643; test accuracy 97.71000146865845; alpha 0.014780882941434608; mu 0\n",
      "Step 50; train loss 0.006733299233019352; train accuracy 100.0; test loss 0.0722522959113121; test accuracy 97.81000018119812; alpha 0.014780882941434608; mu 0\n",
      "Step 100; train loss 0.01585547812283039; train accuracy 100.0; test loss 0.07252828776836395; test accuracy 97.85000085830688; alpha 0.014780882941434608; mu 0\n",
      "Step 150; train loss 0.007291396614164114; train accuracy 100.0; test loss 0.07240939885377884; test accuracy 97.82999753952026; alpha 0.014780882941434608; mu 0\n",
      "Step 200; train loss 0.02103111706674099; train accuracy 99.21875; test loss 0.07073510438203812; test accuracy 97.82000184059143; alpha 0.014780882941434608; mu 0\n",
      "Step 250; train loss 0.026714107021689415; train accuracy 100.0; test loss 0.07192005962133408; test accuracy 97.83999919891357; alpha 0.014780882941434608; mu 0\n",
      "Step 300; train loss 0.006771214306354523; train accuracy 100.0; test loss 0.07179276645183563; test accuracy 97.83999919891357; alpha 0.014780882941434608; mu 0\n",
      "Step 350; train loss 0.019646896049380302; train accuracy 99.21875; test loss 0.07282020151615143; test accuracy 97.8600025177002; alpha 0.014780882941434608; mu 0\n",
      "Step 400; train loss 0.013684363104403019; train accuracy 100.0; test loss 0.07327225059270859; test accuracy 97.79000282287598; alpha 0.014780882941434608; mu 0\n",
      "EPOCH  41  : ##########\n",
      "Step 0; train loss 0.012492123991250992; train accuracy 100.0; test loss 0.07316481322050095; test accuracy 97.75000214576721; alpha 0.013302794647291147; mu 0\n",
      "Step 50; train loss 0.009860634803771973; train accuracy 100.0; test loss 0.07262714952230453; test accuracy 97.72999882698059; alpha 0.013302794647291147; mu 0\n",
      "Step 100; train loss 0.005342090502381325; train accuracy 100.0; test loss 0.07245178520679474; test accuracy 97.85000085830688; alpha 0.013302794647291147; mu 0\n",
      "Step 150; train loss 0.04021919518709183; train accuracy 99.21875; test loss 0.07211910933256149; test accuracy 97.75999784469604; alpha 0.013302794647291147; mu 0\n",
      "Step 200; train loss 0.007232955656945705; train accuracy 100.0; test loss 0.07246652245521545; test accuracy 97.81000018119812; alpha 0.013302794647291147; mu 0\n",
      "Step 250; train loss 0.02978101372718811; train accuracy 99.21875; test loss 0.07223960012197495; test accuracy 97.81000018119812; alpha 0.013302794647291147; mu 0\n",
      "Step 300; train loss 0.006586448755115271; train accuracy 100.0; test loss 0.07309162616729736; test accuracy 97.75999784469604; alpha 0.013302794647291147; mu 0\n",
      "Step 350; train loss 0.006395809352397919; train accuracy 100.0; test loss 0.07348472625017166; test accuracy 97.75999784469604; alpha 0.013302794647291147; mu 0\n",
      "Step 400; train loss 0.015671245753765106; train accuracy 99.21875; test loss 0.07228778302669525; test accuracy 97.83999919891357; alpha 0.013302794647291147; mu 0\n",
      "EPOCH  42  : ##########\n",
      "Step 0; train loss 0.00889426190406084; train accuracy 100.0; test loss 0.07316061854362488; test accuracy 97.75999784469604; alpha 0.011972515182562033; mu 0\n",
      "Step 50; train loss 0.006187001243233681; train accuracy 100.0; test loss 0.0716761127114296; test accuracy 97.79999852180481; alpha 0.011972515182562033; mu 0\n",
      "Step 100; train loss 0.005635550245642662; train accuracy 100.0; test loss 0.0719035267829895; test accuracy 97.78000116348267; alpha 0.011972515182562033; mu 0\n",
      "Step 150; train loss 0.007778286002576351; train accuracy 100.0; test loss 0.0716177225112915; test accuracy 97.82999753952026; alpha 0.011972515182562033; mu 0\n",
      "Step 200; train loss 0.005363133270293474; train accuracy 100.0; test loss 0.07196184247732162; test accuracy 97.79000282287598; alpha 0.011972515182562033; mu 0\n",
      "Step 250; train loss 0.016235074028372765; train accuracy 100.0; test loss 0.07193519920110703; test accuracy 97.76999950408936; alpha 0.011972515182562033; mu 0\n",
      "Step 300; train loss 0.012546362355351448; train accuracy 99.21875; test loss 0.07261642813682556; test accuracy 97.75000214576721; alpha 0.011972515182562033; mu 0\n",
      "Step 350; train loss 0.006867458112537861; train accuracy 100.0; test loss 0.07213752716779709; test accuracy 97.79999852180481; alpha 0.011972515182562033; mu 0\n",
      "Step 400; train loss 0.01594759337604046; train accuracy 99.21875; test loss 0.07259507477283478; test accuracy 97.71000146865845; alpha 0.011972515182562033; mu 0\n",
      "EPOCH  43  : ##########\n",
      "Step 0; train loss 0.012675530277192593; train accuracy 100.0; test loss 0.07207974046468735; test accuracy 97.7400004863739; alpha 0.01077526366430583; mu 0\n",
      "Step 50; train loss 0.023076573386788368; train accuracy 99.21875; test loss 0.07249221205711365; test accuracy 97.76999950408936; alpha 0.01077526366430583; mu 0\n",
      "Step 100; train loss 0.009402405470609665; train accuracy 100.0; test loss 0.07244467735290527; test accuracy 97.71000146865845; alpha 0.01077526366430583; mu 0\n",
      "Step 150; train loss 0.009867643006145954; train accuracy 100.0; test loss 0.07272656261920929; test accuracy 97.72999882698059; alpha 0.01077526366430583; mu 0\n",
      "Step 200; train loss 0.0363420732319355; train accuracy 99.21875; test loss 0.07284639775753021; test accuracy 97.65999913215637; alpha 0.01077526366430583; mu 0\n"
     ]
    }
   ],
   "source": [
    "for meth in algo:\n",
    "    color = col[meth]\n",
    "    if meth == 'Adam':\n",
    "        train_step = tf.train.AdamOptimizer(0.0001).minimize(loss)\n",
    "        epoch = 50\n",
    "        timePlt = collections.deque(maxlen=iterations * epoch)\n",
    "        errPlt = collections.deque(maxlen=iterations * epoch)\n",
    "\n",
    "    else:\n",
    "        m = 4\n",
    "        # mu = 0.8\n",
    "        sk_vec = collections.deque(maxlen=m)\n",
    "        yk_vec = collections.deque(maxlen=m)\n",
    "        Hk_mat = collections.deque(maxlen=1)\n",
    "        alpha_k = collections.deque(maxlen=1)\n",
    "        mu_val = collections.deque(maxlen=1)\n",
    "\n",
    "        timePlt = collections.deque(maxlen=iterations * epoch)\n",
    "        errPlt = collections.deque(maxlen=iterations * epoch)\n",
    "\n",
    "        alpha_k.append(1)\n",
    "        vk_vec = collections.deque(maxlen=1)\n",
    "        vk_vec.append(0)\n",
    "        dirNorm = True\n",
    "\n",
    "        if meth == 'oNAQ' or meth == 'oBFGS' or meth == 'oLNAQ' or meth == 'oLBFGS':  # vk_vec=None, sk_vec=None, yk_vec=None, m=8, alpha_k=1.0, mu=None, dirNorm=True,\n",
    "\n",
    "            train_step = tf.contrib.opt.ScipyOptimizerInterface(\n",
    "                loss, method=meth.lower(),\n",
    "                options={'maxiter': iterations, 'disp': False, 'vk_vec': vk_vec, 'sk_vec': sk_vec, 'yk_vec': yk_vec,\n",
    "                         'timeplot': timePlt, 'err': errPlt, 'Hk_mat':Hk_mat,\n",
    "                         'm': m, 'alpha_k': alpha_k, 'muk': mu_val, 'dirNorm': dirNorm})\n",
    "\n",
    "        elif meth == 'oMoQ' or meth == 'oLMoQ':  # vk_vec=None, sk_vec=None, yk_vec=None, m=8, alpha_k=1.0, mu=None, dirNorm=True,\n",
    "            # grad_curr = collections.deque(maxlen=1)\n",
    "            # grad_pre = collections.deque(maxlen=1)\n",
    "            gfk_vec = collections.deque(maxlen=2)\n",
    "\n",
    "            train_step = tf.contrib.opt.ScipyOptimizerInterface(\n",
    "                loss, method=meth.lower(),\n",
    "                options={'maxiter': iterations, 'disp': False, 'vk_vec': vk_vec, 'sk_vec': sk_vec, 'yk_vec': yk_vec,\n",
    "                         # 'grad_pre': grad_pre, 'grad_curr': grad_curr,\n",
    "                         'timeplot': timePlt, 'err': errPlt, 'gfk_vec': gfk_vec,'Hk_mat':Hk_mat,\n",
    "                         'm': m, 'alpha_k': alpha_k, 'muk': mu_val, 'dirNorm': dirNorm})\n",
    "\n",
    "    sess = tf.InteractiveSession()\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    print(\"Initial Error of \", meth, \" : \", sess.run(loss, feed_dict={training_data: Xtrain, labels: Ytrain}))\n",
    "\n",
    "    step = 0\n",
    "    alpha_k.append(1)\n",
    "    eta0 = batch_size / (batch_size + 2)\n",
    "\n",
    "    test_acc_plot = []\n",
    "    test_loss_plot = []\n",
    "    train_acc_plot = []\n",
    "    train_loss_plot = []\n",
    "\n",
    "    for ep in range(1, epoch + 1):\n",
    "        print(\"EPOCH \", ep, \" : ##########\")\n",
    "        theta_k = 1\n",
    "\n",
    "        alpha_k.append(alpha_k[-1] * 0.9)\n",
    "        alpha_k.append(np.maximum(alpha_k[-1],0.001))\n",
    "        # alpha_k.append(0.5)\n",
    "        Xtr, Ytr = get_batches(Xtrain, Ytrain, batch_size, ep)\n",
    "        for i in range(iterations):\n",
    "            step += 1\n",
    "\n",
    "            data, lab = Xtr[i], Ytr[i]\n",
    "            feed_dict = {training_data: data, labels: lab}\n",
    "\n",
    "            if meth == 'Adam':\n",
    "                start = time.time()\n",
    "                _, train_loss, train_acc = sess.run([train_step, loss, accuracy], feed_dict=feed_dict)\n",
    "                end = time.time()\n",
    "                timePlt.append(end - start)\n",
    "\n",
    "\n",
    "\n",
    "            else:\n",
    "\n",
    "                if meth != 'oMoQ' or meth != 'oLMoQ':\n",
    "                    if step > 1:\n",
    "                        alpha_k.append(1 / np.sqrt(step))\n",
    "\n",
    "                    # if meth == 'oMoQ':\n",
    "                    #  if step > 1:\n",
    "                    #    alpha_k.append(10 / (10+step))\n",
    "\n",
    "                if meth == 'oBFGS' or meth == 'oLBFGS':\n",
    "                    alpha_k.append(eta0 * (10 / (10 + step)))\n",
    "                    mu_val.append(0)\n",
    "                    mu = mu_val[-1]\n",
    "\n",
    "                if meth == 'oNAQ' or meth == 'oLNAQ':\n",
    "\n",
    "                    mu_val.append(0.8)\n",
    "                    mu = mu_val[-1]\n",
    "\n",
    "                if meth == 'oMoQ' or meth == 'oLMoQ':\n",
    "                    # theta_kp1 = ((1e-5 - (theta_k * theta_k)) + np.sqrt(((1e-5 - (theta_k * theta_k)) * (1e-5 - (theta_k * theta_k))) + 4 * theta_k * theta_k)) / 2\n",
    "                    # mu = np.minimum((theta_k * (1 - theta_k)) / (theta_k * theta_k + theta_kp1), 0.95)\n",
    "                    # theta_k = theta_kp1\n",
    "\n",
    "                    mu_val.append(0.8)\n",
    "                    mu = mu_val[-1]\n",
    "\n",
    "                res = train_step.minimize(sess, fetches=[loss, accuracy],\n",
    "                                          loss_callback=update,\n",
    "                                          feed_dict=feed_dict)\n",
    "\n",
    "            test_loss, test_acc = sess.run([loss, accuracy], feed_dict={training_data: Xtest, labels: Ytest})\n",
    "            test_acc_plot.append(test_acc * 100)\n",
    "            test_loss_plot.append(test_loss)\n",
    "            train_acc_plot.append(train_acc * 100)\n",
    "            train_loss_plot.append(train_loss)\n",
    "\n",
    "            if i % 50 == 0:\n",
    "                print(\n",
    "                    'Step {}; train loss {}; train accuracy {}; test loss {}; test accuracy {}; alpha {}; mu {}'.format(\n",
    "                        i, train_loss, train_acc * 100, test_loss, test_acc * 100, alpha_k[0], mu))\n",
    "\n",
    "    leg = algo\n",
    "\n",
    "    plt.figure(1)\n",
    "    plt.semilogy(np.cumsum(timePlt), train_loss_plot, color)\n",
    "    plt.xlabel('Time')\n",
    "    plt.ylabel('Training Loss')\n",
    "    plt.legend(leg)\n",
    "    plt.tight_layout()\n",
    "\n",
    "    plt.figure(2)\n",
    "    plt.semilogy(np.cumsum(timePlt), test_loss_plot, color)\n",
    "    plt.xlabel('Time')\n",
    "    plt.ylabel('Test Loss')\n",
    "    plt.legend(leg)\n",
    "    plt.tight_layout()\n",
    "\n",
    "    plt.figure(3)\n",
    "    plt.plot(np.cumsum(timePlt), train_acc_plot, color)\n",
    "    plt.ylim((70, 100))\n",
    "    plt.xlabel('Time')\n",
    "    plt.ylabel('Train Accuracy')\n",
    "    plt.legend(leg)\n",
    "    plt.tight_layout()\n",
    "\n",
    "    plt.figure(4)\n",
    "    plt.plot(np.cumsum(timePlt), test_acc_plot, color)\n",
    "    plt.ylim((70, 100))\n",
    "    plt.xlabel('Time')\n",
    "    plt.ylabel('Test Accuracy')\n",
    "    plt.legend(leg)\n",
    "    plt.tight_layout()\n",
    "\n",
    "    plt.figure(5)\n",
    "    plt.semilogy(train_loss_plot, color)\n",
    "    plt.xlabel('Iteration')\n",
    "    plt.ylabel('Training Loss')\n",
    "    plt.legend(leg)\n",
    "    plt.tight_layout()\n",
    "\n",
    "    plt.figure(6)\n",
    "    plt.semilogy(test_loss_plot, color)\n",
    "    plt.xlabel('Iteration')\n",
    "    plt.ylabel('Test Loss')\n",
    "    plt.legend(leg)\n",
    "    plt.tight_layout()\n",
    "\n",
    "    plt.figure(7)\n",
    "    plt.plot(train_acc_plot, color)\n",
    "    # plt.ylim((70,100))\n",
    "    plt.xlabel('Iteration')\n",
    "    plt.ylabel('Train Accuracy')\n",
    "    plt.legend(leg)\n",
    "    plt.tight_layout()\n",
    "\n",
    "    plt.figure(8)\n",
    "    plt.plot(test_acc_plot, color)\n",
    "    plt.ylim((60,100))\n",
    "    plt.xlabel('Iteration')\n",
    "    plt.ylabel('Test Accuracy')\n",
    "    plt.legend(leg)\n",
    "    plt.tight_layout()\n",
    "\n",
    "    plt.figure(9)\n",
    "    plt.semilogy(np.cumsum(timePlt), np.minimum.accumulate(train_loss_plot), color)\n",
    "    plt.xlabel('Time')\n",
    "    plt.ylabel('Training Loss')\n",
    "    plt.legend(leg)\n",
    "    plt.tight_layout()\n",
    "\n",
    "    plt.figure(10)\n",
    "    plt.semilogy(np.cumsum(timePlt), np.minimum.accumulate(test_loss_plot), color)\n",
    "    plt.xlabel('Time')\n",
    "    plt.ylabel('Test Loss')\n",
    "    plt.legend(leg)\n",
    "    plt.tight_layout()\n",
    "\n",
    "    plt.figure(11)\n",
    "    plt.plot(np.cumsum(timePlt), np.maximum.accumulate(train_acc_plot), color)\n",
    "    plt.ylim((40, 100))\n",
    "    plt.xlabel('Time')\n",
    "    plt.ylabel('Train Accuracy')\n",
    "    plt.legend(leg)\n",
    "    plt.tight_layout()\n",
    "\n",
    "    plt.figure(12)\n",
    "    plt.plot(np.cumsum(timePlt), np.maximum.accumulate(test_acc_plot), color)\n",
    "    plt.ylim((40, 100))\n",
    "    plt.xlabel('Time')\n",
    "    plt.ylabel('Test Accuracy')\n",
    "    plt.legend(leg)\n",
    "    plt.tight_layout()\n",
    "\n",
    "    plt.figure(13)\n",
    "    plt.semilogy(np.minimum.accumulate(train_loss_plot), color)\n",
    "    plt.xlabel('Iteration')\n",
    "    plt.ylabel('Training Loss')\n",
    "    plt.legend(leg)\n",
    "    plt.tight_layout()\n",
    "\n",
    "    plt.figure(14)\n",
    "    plt.semilogy(np.minimum.accumulate(test_loss_plot), color)\n",
    "    plt.xlabel('Iteration')\n",
    "    plt.ylabel('Test Loss')\n",
    "    plt.legend(leg)\n",
    "    plt.tight_layout()\n",
    "\n",
    "    plt.figure(15)\n",
    "    plt.plot(np.maximum.accumulate(train_acc_plot), color)\n",
    "    plt.ylim((40, 105))\n",
    "    plt.xlabel('Iteration')\n",
    "    plt.ylabel('Train Accuracy')\n",
    "    plt.legend(leg)\n",
    "    plt.tight_layout()\n",
    "\n",
    "    plt.figure(16)\n",
    "    plt.plot(np.maximum.accumulate(test_acc_plot), color)\n",
    "    plt.ylim((40, 100))\n",
    "    plt.xlabel('Iteration')\n",
    "    plt.ylabel('Test Accuracy')\n",
    "    plt.legend(leg)\n",
    "    plt.tight_layout()\n",
    "\n",
    "    timePlt.clear()\n",
    "    sk_vec.clear()\n",
    "    yk_vec.clear()\n",
    "    vk_vec.clear()\n",
    "\n",
    "    sess.close()\n",
    "\n",
    "print('seed: ', seed)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "qtmModdDEc-y"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "oMoQ_28x28Mnist.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
